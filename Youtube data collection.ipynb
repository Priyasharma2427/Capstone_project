{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, We are trying to get the transcript of the video id using the .get_transcript() function.\n",
    "#### It returns us a list of dictionaries in which each dictionary contains 3 key-value pair inside it, the first one being the content, the second one being the time instant from which the caption sentence/phrase start to be spoken and the third one being the duration in seconds that is taken to speak the sentence or phrase completely.\n",
    "#### First-line basically imports the required packages and the next line assigns a variable to store the list of dictionaries and finally on the 3rd line it prints out the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"in this video we're gonna build the\", 'start': 0.22, 'duration': 4.44}, {'text': 'transformer Network from scratch from', 'start': 2.77, 'duration': 3.779}, {'text': 'the original paper attention is all you', 'start': 4.66, 'duration': 4.05}, {'text': 'need which is one of the most impactful', 'start': 6.549, 'duration': 3.63}, {'text': 'papers in deep learning and natural', 'start': 8.71, 'duration': 3.45}, {'text': \"language processing let's roll that\", 'start': 10.179, 'duration': 13.321}, {'text': \"intro and then let's get started what is\", 'start': 12.16, 'duration': 13.32}, {'text': \"going on guys hope you're doing awesome\", 'start': 23.5, 'duration': 4.56}, {'text': \"so we're gonna start with taking a look\", 'start': 25.48, 'duration': 4.44}, {'text': 'at the paper and getting an', 'start': 28.06, 'duration': 3.629}, {'text': \"understanding of what we're gonna do and\", 'start': 29.92, 'duration': 3.84}, {'text': \"I'm gonna try to explain two relevant\", 'start': 31.689, 'duration': 4.681}, {'text': 'parts and I do think when we step', 'start': 33.76, 'duration': 3.99}, {'text': \"through the code it's gonna help with\", 'start': 36.37, 'duration': 3.15}, {'text': 'the understanding as well but if you', 'start': 37.75, 'duration': 3.51}, {'text': 'still have questions about how', 'start': 39.52, 'duration': 4.469}, {'text': 'transformers work and then I recommend', 'start': 41.26, 'duration': 5.369}, {'text': \"this blog post by Peter bloom and it's\", 'start': 43.989, 'duration': 4.41}, {'text': 'one of the resources I used to gain a', 'start': 46.629, 'duration': 4.441}, {'text': 'better understanding of transformers so', 'start': 48.399, 'duration': 4.951}, {'text': \"with that said let's start with taking a\", 'start': 51.07, 'duration': 4.559}, {'text': 'look at the paper so the paper is', 'start': 53.35, 'duration': 4.95}, {'text': 'attention is all you need and as I said', 'start': 55.629, 'duration': 4.441}, {'text': \"it's one of the most impactful paper in\", 'start': 58.3, 'duration': 4.05}, {'text': 'deep learning and especially for natural', 'start': 60.07, 'duration': 4.47}, {'text': \"language processing so we're just gonna\", 'start': 62.35, 'duration': 5.07}, {'text': 'go down to the overview of the', 'start': 64.54, 'duration': 5.28}, {'text': 'transformer here and if this is the', 'start': 67.42, 'duration': 4.41}, {'text': 'first time that you see the transformer', 'start': 69.82, 'duration': 5.04}, {'text': 'network this is gonna feel very scary at', 'start': 71.83, 'duration': 5.28}, {'text': \"least it did for me and it's kinda looks\", 'start': 74.86, 'duration': 4.17}, {'text': 'like some stuff from the matrix that you', 'start': 77.11, 'duration': 5.01}, {'text': \"can never understand but trust me we're\", 'start': 79.03, 'duration': 5.54}, {'text': 'gonna try to go through it step-by-step', 'start': 82.12, 'duration': 5.25}, {'text': 'so the first thing is that you know we', 'start': 84.57, 'duration': 6.06}, {'text': 'have to the left here we have a encoder', 'start': 87.37, 'duration': 6.36}, {'text': 'alright and then we have a decoder to', 'start': 90.63, 'duration': 5.98}, {'text': 'the right so hopefully you have a bit', 'start': 93.73, 'duration': 4.59}, {'text': 'understanding of sequence of sequence', 'start': 96.61, 'duration': 3.9}, {'text': 'and sequences sequence with attention', 'start': 98.32, 'duration': 5.52}, {'text': \"and if not I've made previous videos on\", 'start': 100.51, 'duration': 5.34}, {'text': 'those', 'start': 103.84, 'duration': 4.68}, {'text': 'but you know that this right here is the', 'start': 105.85, 'duration': 4.74}, {'text': 'encoder and so starting from the bottom', 'start': 108.52, 'duration': 4.2}, {'text': \"we have some input let's say it's some\", 'start': 110.59, 'duration': 5.01}, {'text': 'source text and we you know so for', 'start': 112.72, 'duration': 5.91}, {'text': \"machine translation we're gonna create\", 'start': 115.6, 'duration': 5.91}, {'text': 'our create some embeddings and then', 'start': 118.63, 'duration': 4.86}, {'text': \"that's going to be sent in to this block\", 'start': 121.51, 'duration': 3.87}, {'text': \"right here alright and we're gonna call\", 'start': 123.49, 'duration': 5.7}, {'text': 'this block to transform a block okay so', 'start': 125.38, 'duration': 5.22}, {'text': \"let's just restrict our attention to\", 'start': 129.19, 'duration': 4.05}, {'text': 'just this block right here what we can', 'start': 130.6, 'duration': 7.14}, {'text': 'see first is that the the input is going', 'start': 133.24, 'duration': 6.03}, {'text': 'to be sent into some multi-headed', 'start': 137.74, 'duration': 2.94}, {'text': 'attention okay', 'start': 139.27, 'duration': 3.33}, {'text': 'and this multi-headed attention this', 'start': 140.68, 'duration': 4.529}, {'text': 'this is you know smaller block inside', 'start': 142.6, 'duration': 5.88}, {'text': 'this transformer block is perhaps well', 'start': 145.209, 'duration': 5.341}, {'text': \"it is the most difficult part and it's\", 'start': 148.48, 'duration': 4.11}, {'text': 'the essential core of the transformer', 'start': 150.55, 'duration': 5.33}, {'text': 'alright so if we understand this', 'start': 152.59, 'duration': 6.27}, {'text': 'everything else is going to be easy so', 'start': 155.88, 'duration': 5.109}, {'text': 'what we can see first is that we have', 'start': 158.86, 'duration': 4.59}, {'text': 'some input and what this is gonna do is', 'start': 160.989, 'duration': 4.441}, {'text': 'gonna send into three different inputs', 'start': 163.45, 'duration': 4.05}, {'text': \"to the multi-headed attention we're\", 'start': 165.43, 'duration': 4.44}, {'text': 'gonna call these the values the keys and', 'start': 167.5, 'duration': 5.73}, {'text': 'the queries alright for the first one as', 'start': 169.87, 'duration': 5.55}, {'text': \"we just have one input here it's gonna\", 'start': 173.23, 'duration': 4.35}, {'text': 'be the same input for all three of those', 'start': 175.42, 'duration': 4.349}, {'text': \"so we're just gonna you know repeat it\", 'start': 177.58, 'duration': 5.129}, {'text': 'and send the same input for all three of', 'start': 179.769, 'duration': 6.241}, {'text': 'these value key enquiry', 'start': 182.709, 'duration': 5.31}, {'text': \"all right we're gonna go to the multi\", 'start': 186.01, 'duration': 4.02}, {'text': 'attention in more detail but and this is', 'start': 188.019, 'duration': 3.991}, {'text': \"sort of just the overview in that that's\", 'start': 190.03, 'duration': 5.429}, {'text': \"the most important part and then what's\", 'start': 192.01, 'duration': 4.71}, {'text': \"gonna happen is it's just going to go\", 'start': 195.459, 'duration': 3.81}, {'text': \"through a normalization then it's gonna\", 'start': 196.72, 'duration': 4.29}, {'text': 'go through a feed-forward Network and', 'start': 199.269, 'duration': 3.36}, {'text': \"it's gonna go to another normalization\", 'start': 201.01, 'duration': 3.93}, {'text': 'all right these three parts are very', 'start': 202.629, 'duration': 5.791}, {'text': \"easy to understand and I think it's\", 'start': 204.94, 'duration': 4.74}, {'text': 'going to be clear as well when we go', 'start': 208.42, 'duration': 3.569}, {'text': \"through the code all right so that's\", 'start': 209.68, 'duration': 5.729}, {'text': 'sort of the the the understanding part', 'start': 211.989, 'duration': 5.131}, {'text': \"of what we're going to do here then\", 'start': 215.409, 'duration': 5.67}, {'text': \"there's these arrows here which if you\", 'start': 217.12, 'duration': 6.06}, {'text': 'familiar would resonate these are just', 'start': 221.079, 'duration': 4.05}, {'text': 'skip connections so that we have our', 'start': 223.18, 'duration': 3.75}, {'text': 'input here which is sent through a', 'start': 225.129, 'duration': 3.991}, {'text': 'multi-headed attention and then the', 'start': 226.93, 'duration': 4.619}, {'text': 'output from that is going to be sent to', 'start': 229.12, 'duration': 5.22}, {'text': 'this norm this this normalization right', 'start': 231.549, 'duration': 4.701}, {'text': \"here but we're also going to take this\", 'start': 234.34, 'duration': 5.009}, {'text': 'skip connection from the previous so the', 'start': 236.25, 'duration': 4.959}, {'text': 'input before the multi-headed attention', 'start': 239.349, 'duration': 3.811}, {'text': \"and that's also going to be sent into\", 'start': 241.209, 'duration': 4.801}, {'text': 'the normalization so just like resonates', 'start': 243.16, 'duration': 4.669}, {'text': \"we're going to add them together and\", 'start': 246.01, 'duration': 4.74}, {'text': 'similarly this error here is also a skip', 'start': 247.829, 'duration': 5.38}, {'text': 'connection so before we run it through', 'start': 250.75, 'duration': 4.44}, {'text': \"the feed-forward we're gonna take that\", 'start': 253.209, 'duration': 3.571}, {'text': \"the input to the feed forward we're\", 'start': 255.19, 'duration': 3.81}, {'text': 'gonna send it through with this cab skip', 'start': 256.78, 'duration': 4.41}, {'text': 'connection to the normalization and then', 'start': 259.0, 'duration': 3.75}, {'text': \"we're also gonna add it with the output\", 'start': 261.19, 'duration': 4.74}, {'text': 'from the feed-forward Network all right', 'start': 262.75, 'duration': 5.43}, {'text': \"so that's a transform a block and we're\", 'start': 265.93, 'duration': 3.66}, {'text': 'going to go through the attention part', 'start': 268.18, 'duration': 4.44}, {'text': 'in more detail and also the feed-forward', 'start': 269.59, 'duration': 5.4}, {'text': 'part but the again this is easy this', 'start': 272.62, 'duration': 4.109}, {'text': 'multi-headed attention is the difficult', 'start': 274.99, 'duration': 5.549}, {'text': 'part then for the decoder right here we', 'start': 276.729, 'duration': 5.431}, {'text': 'can see first of all that the output', 'start': 280.539, 'duration': 6.781}, {'text': 'from the the the encoder is sent as', 'start': 282.16, 'duration': 7.86}, {'text': 'input so if you remember these are the', 'start': 287.32, 'duration': 5.37}, {'text': 'values keys and queries so the output', 'start': 290.02, 'duration': 4.95}, {'text': 'from the encoder is gonna be sent into', 'start': 292.69, 'duration': 5.31}, {'text': 'some multi-headed attention here for the', 'start': 294.97, 'duration': 6.12}, {'text': 'values and the and the keys and then the', 'start': 298.0, 'duration': 5.16}, {'text': 'query is here for the multi detention is', 'start': 301.09, 'duration': 4.38}, {'text': 'gonna be sent from from the previous', 'start': 303.16, 'duration': 6.06}, {'text': \"part of the decoder but let's look again\", 'start': 305.47, 'duration': 6.629}, {'text': \"so we have a let's call it a decoder\", 'start': 309.22, 'duration': 7.86}, {'text': 'block right here and what it uses is', 'start': 312.099, 'duration': 6.75}, {'text': \"first of all right here it's the\", 'start': 317.08, 'duration': 3.899}, {'text': 'transformer block this is the exact same', 'start': 318.849, 'duration': 6.181}, {'text': 'part as we saw in the encoder right the', 'start': 320.979, 'duration': 6.571}, {'text': \"only thing that's changed here is that\", 'start': 325.03, 'duration': 6.21}, {'text': 'we have now different inputs to the', 'start': 327.55, 'duration': 5.7}, {'text': 'attention here where two of them are', 'start': 331.24, 'duration': 4.079}, {'text': 'from the previous encoder and one of', 'start': 333.25, 'duration': 4.199}, {'text': 'them is from the previous part of the', 'start': 335.319, 'duration': 3.801}, {'text': 'decoder', 'start': 337.449, 'duration': 4.041}, {'text': 'so what we can say is that the decoder', 'start': 339.12, 'duration': 5.1}, {'text': 'block right here is this transformer', 'start': 341.49, 'duration': 4.92}, {'text': 'block and it has two additional ones so', 'start': 344.22, 'duration': 6.13}, {'text': 'the normalization and another attention', 'start': 346.41, 'duration': 7.27}, {'text': 'so you know this is pretty much the same', 'start': 350.35, 'duration': 5.64}, {'text': 'here we have the embedding for the for', 'start': 353.68, 'duration': 6.72}, {'text': 'the output and then we send it into this', 'start': 355.99, 'duration': 6.48}, {'text': \"attention right here we're gonna again\", 'start': 360.4, 'duration': 4.22}, {'text': 'send the same thing through everything', 'start': 362.47, 'duration': 4.53}, {'text': 'every like the value key in query and', 'start': 364.62, 'duration': 4.15}, {'text': \"then we're gonna have this skipped\", 'start': 367.0, 'duration': 3.45}, {'text': 'connection again to normalization and', 'start': 368.77, 'duration': 4.95}, {'text': 'and then this skip connection right here', 'start': 370.45, 'duration': 5.01}, {'text': 'is gonna come from this previous part', 'start': 373.72, 'duration': 5.55}, {'text': 'here and the values and keys come from', 'start': 375.46, 'duration': 6.96}, {'text': 'the output from the encoder and then the', 'start': 379.27, 'duration': 6.42}, {'text': 'query here comes from this part and then', 'start': 382.42, 'duration': 4.02}, {'text': \"we're gonna send it through a\", 'start': 385.69, 'duration': 3.54}, {'text': 'transformer block and then unless then', 'start': 386.44, 'duration': 4.38}, {'text': \"finally we're gonna send it through some\", 'start': 389.23, 'duration': 5.45}, {'text': 'linear and some softmax all right so', 'start': 390.82, 'duration': 6.33}, {'text': 'before we step you know go through the', 'start': 394.68, 'duration': 4.06}, {'text': 'attention part in a little bit more', 'start': 397.15, 'duration': 4.38}, {'text': 'detail first of all if we have this NX', 'start': 398.74, 'duration': 6.75}, {'text': 'right here which is this block which we', 'start': 401.53, 'duration': 6.0}, {'text': 'call the decoder block is going to be', 'start': 405.49, 'duration': 4.64}, {'text': 'repeated a couple of times all right and', 'start': 407.53, 'duration': 5.55}, {'text': 'similarly for the encoder so you know', 'start': 410.13, 'duration': 4.72}, {'text': 'instead of having just one of these', 'start': 413.08, 'duration': 3.78}, {'text': 'blocks and then send that out put it', 'start': 414.85, 'duration': 5.01}, {'text': \"through the decoder we're gonna do that\", 'start': 416.86, 'duration': 5.72}, {'text': 'this block right here is gonna be the', 'start': 419.86, 'duration': 4.92}, {'text': 'output from this block is gonna be sent', 'start': 422.58, 'duration': 4.3}, {'text': 'to another identical of these blocks and', 'start': 424.78, 'duration': 4.68}, {'text': 'then for a couple of times in a couple', 'start': 426.88, 'duration': 4.86}, {'text': 'of couple of layers and then the output', 'start': 429.46, 'duration': 4.47}, {'text': 'from that final block will be sent to', 'start': 431.74, 'duration': 4.26}, {'text': 'the to the decoder', 'start': 433.93, 'duration': 4.41}, {'text': \"alright that's just what the NX stands\", 'start': 436.0, 'duration': 5.58}, {'text': 'for here so we repeat this for a couple', 'start': 438.34, 'duration': 7.24}, {'text': 'of times couple of layers', 'start': 441.58, 'duration': 5.829}, {'text': \"and I guess the only thing we didn't\", 'start': 445.58, 'duration': 4.95}, {'text': 'talk about here is that button so this', 'start': 447.409, 'duration': 5.91}, {'text': 'positional encoding the transformer', 'start': 450.53, 'duration': 5.849}, {'text': 'network is permutation aliy invariant so', 'start': 453.319, 'duration': 6.75}, {'text': 'if you have a sentence and you change', 'start': 456.379, 'duration': 6.151}, {'text': 'the order of the words that means that', 'start': 460.069, 'duration': 4.171}, {'text': 'you know the transformer will be', 'start': 462.53, 'duration': 4.71}, {'text': \"invariant to those changes it's going to\", 'start': 464.24, 'duration': 5.07}, {'text': 'be the exact same output even if you', 'start': 467.24, 'duration': 3.72}, {'text': 'change the order of the words which is', 'start': 469.31, 'duration': 3.389}, {'text': 'not good right because if you change the', 'start': 470.96, 'duration': 4.169}, {'text': 'order of a few words that can entirely', 'start': 472.699, 'duration': 5.19}, {'text': 'change the meaning of the sentence so we', 'start': 475.129, 'duration': 5.57}, {'text': 'have these positional encodings and', 'start': 477.889, 'duration': 5.701}, {'text': \"we're gonna this is sort of like an\", 'start': 480.699, 'duration': 5.59}, {'text': 'embedding that we we add in back to the', 'start': 483.59, 'duration': 6.24}, {'text': 'input embedding so that it becomes aware', 'start': 486.289, 'duration': 7.711}, {'text': \"of the positions of the words and we're\", 'start': 489.83, 'duration': 5.91}, {'text': \"gonna use a we're going to implement a\", 'start': 494.0, 'duration': 3.24}, {'text': \"variant that's a little bit easier than\", 'start': 495.74, 'duration': 3.149}, {'text': \"they did in the paper we're gonna use\", 'start': 497.24, 'duration': 3.66}, {'text': \"positional embeddings and we're going to\", 'start': 498.889, 'duration': 3.691}, {'text': 'go through that more when we when we', 'start': 500.9, 'duration': 2.609}, {'text': 'talk and we can go through the', 'start': 502.58, 'duration': 2.9}, {'text': 'implementation', 'start': 503.509, 'duration': 4.041}, {'text': \"but I think yeah so there's one more\", 'start': 505.48, 'duration': 4.02}, {'text': 'thing in that this attention right here', 'start': 507.55, 'duration': 5.67}, {'text': 'is a masked multi head attention so', 'start': 509.5, 'duration': 5.31}, {'text': \"let's just step back a little to\", 'start': 513.22, 'duration': 3.69}, {'text': 'understand this masking so the thing', 'start': 514.81, 'duration': 3.87}, {'text': 'about transformers that made them so', 'start': 516.91, 'duration': 4.2}, {'text': 'great is the fact that all operations', 'start': 518.68, 'duration': 5.1}, {'text': 'are able to be done in parallel which is', 'start': 521.11, 'duration': 5.01}, {'text': 'in contrast to sequence models like LST', 'start': 523.78, 'duration': 5.46}, {'text': \"Msgr use in our Nan's but this really\", 'start': 526.12, 'duration': 5.1}, {'text': 'you know really big strength has one', 'start': 529.24, 'duration': 3.9}, {'text': 'problem which is if we look at', 'start': 531.22, 'duration': 3.96}, {'text': 'translation where we have a target', 'start': 533.14, 'duration': 5.16}, {'text': 'translated text this translated text is', 'start': 535.18, 'duration': 5.43}, {'text': 'all sent into decoder at the same time', 'start': 538.3, 'duration': 4.32}, {'text': \"so you know let's just say that the\", 'start': 540.61, 'duration': 3.75}, {'text': 'first element is a star token and then', 'start': 542.62, 'duration': 3.9}, {'text': 'the next element is the first translated', 'start': 544.36, 'duration': 5.22}, {'text': 'word and then the first output that', 'start': 546.52, 'duration': 5.04}, {'text': \"we've worn from the decoder just\", 'start': 549.58, 'duration': 4.23}, {'text': 'corresponds to the second element which', 'start': 551.56, 'duration': 5.07}, {'text': 'we send in in the target sentence so if', 'start': 553.81, 'duration': 4.95}, {'text': 'we allow the encoder to have all this', 'start': 556.63, 'duration': 4.29}, {'text': 'information this is going to be super', 'start': 558.76, 'duration': 4.26}, {'text': 'easy simple it will just learn to use', 'start': 560.92, 'duration': 4.59}, {'text': 'the provided target translation and it', 'start': 563.02, 'duration': 4.76}, {'text': 'will just learn a simple mapping and', 'start': 565.51, 'duration': 4.67}, {'text': 'really not learn anything about', 'start': 567.78, 'duration': 5.35}, {'text': 'translating text so what we do is that', 'start': 570.18, 'duration': 6.04}, {'text': 'we mask the target input to the decoder', 'start': 573.13, 'duration': 5.67}, {'text': 'so that the first output of the decoder', 'start': 576.22, 'duration': 5.61}, {'text': 'only had access to the first element and', 'start': 578.8, 'duration': 6.06}, {'text': 'then the second output only had access', 'start': 581.83, 'duration': 6.27}, {'text': 'to the first and second you know input', 'start': 584.86, 'duration': 5.94}, {'text': 'to the decoder now that we have an', 'start': 588.1, 'duration': 4.68}, {'text': \"overview let's try to take a deeper look\", 'start': 590.8, 'duration': 4.5}, {'text': 'at the attention mechanism so the', 'start': 592.78, 'duration': 4.44}, {'text': \"absolute first thing we're gonna do is\", 'start': 595.3, 'duration': 4.74}, {'text': \"we're gonna take the embedding input and\", 'start': 597.22, 'duration': 5.64}, {'text': \"let's say it's 256 dimensions and we're\", 'start': 600.04, 'duration': 5.19}, {'text': 'going to split it into several parts so', 'start': 602.86, 'duration': 4.89}, {'text': \"let's say we split into eight parts now\", 'start': 605.23, 'duration': 5.16}, {'text': 'eight of these parts all have 32', 'start': 607.75, 'duration': 3.45}, {'text': 'dimensions', 'start': 610.39, 'duration': 3.87}, {'text': \"32 dimensions each and they're all going\", 'start': 611.2, 'duration': 4.89}, {'text': 'to be sent in three through linear', 'start': 614.26, 'duration': 4.74}, {'text': \"layers and that's also why we have this\", 'start': 616.09, 'duration': 6.75}, {'text': \"linear shadow'd parts here is because we\", 'start': 619.0, 'duration': 6.66}, {'text': 'are sending in the input which has been', 'start': 622.84, 'duration': 7.29}, {'text': 'split and then we send the output from', 'start': 625.66, 'duration': 6.63}, {'text': 'those into this scaled dot product', 'start': 630.13, 'duration': 4.17}, {'text': 'attention all right and they have a', 'start': 632.29, 'duration': 3.9}, {'text': 'figure here but I think the formula is a', 'start': 634.3, 'duration': 3.42}, {'text': 'little bit clearer', 'start': 636.19, 'duration': 3.99}, {'text': 'so essentially the attention the scale', 'start': 637.72, 'duration': 4.739}, {'text': 'dot-product attention is that we take', 'start': 640.18, 'duration': 4.38}, {'text': 'the queries and we multiply them with', 'start': 642.459, 'duration': 5.221}, {'text': 'the keys then we do a scaling which is', 'start': 644.56, 'duration': 5.129}, {'text': 'that we divide by the square root of the', 'start': 647.68, 'duration': 4.44}, {'text': 'embedding size essentially this is just', 'start': 649.689, 'duration': 5.34}, {'text': 'for numerical stability then we do a', 'start': 652.12, 'duration': 6.54}, {'text': 'soft max of that and lastly we multiply', 'start': 655.029, 'duration': 7.021}, {'text': \"it with the values okay that's the scale\", 'start': 658.66, 'duration': 6.719}, {'text': 'dot product attention so we do then is', 'start': 662.05, 'duration': 5.31}, {'text': 'that we concatenate all of those all of', 'start': 665.379, 'duration': 4.71}, {'text': 'those different parts that we split so', 'start': 667.36, 'duration': 4.89}, {'text': 'that we obtain the same as the as the', 'start': 670.089, 'duration': 5.25}, {'text': 'input so the embedding size and then', 'start': 672.25, 'duration': 5.519}, {'text': 'that is then sent through a linear layer', 'start': 675.339, 'duration': 4.35}, {'text': \"and that's the output from the\", 'start': 677.769, 'duration': 3.841}, {'text': 'multi-headed attention now that we have', 'start': 679.689, 'duration': 4.681}, {'text': 'a basic understanding of the transformer', 'start': 681.61, 'duration': 4.8}, {'text': \"Network we're ready to start coding so\", 'start': 684.37, 'duration': 4.23}, {'text': \"there are a bunch of things I didn't\", 'start': 686.41, 'duration': 4.169}, {'text': 'mention in the implementation details', 'start': 688.6, 'duration': 5.039}, {'text': \"and I'm gonna sort of talk about them as\", 'start': 690.579, 'duration': 5.7}, {'text': 'we go through it and but I think that', 'start': 693.639, 'duration': 4.62}, {'text': 'the necessary understanding is there for', 'start': 696.279, 'duration': 4.381}, {'text': \"us to start coding it so what we're\", 'start': 698.259, 'duration': 3.81}, {'text': \"going to do first is we're gonna do as\", 'start': 700.66, 'duration': 4.59}, {'text': \"usual import torch we're gonna do import\", 'start': 702.069, 'duration': 7.08}, {'text': \"torch n N as n N and the thing we're\", 'start': 705.25, 'duration': 5.97}, {'text': 'gonna start with which is perhaps the', 'start': 709.149, 'duration': 4.5}, {'text': 'most complicated thing is a self', 'start': 711.22, 'duration': 5.489}, {'text': \"attention so we're going to class self\", 'start': 713.649, 'duration': 6.451}, {'text': \"attention we're going to inherit from an\", 'start': 716.709, 'duration': 6.271}, {'text': \"in module and we're going to do define\", 'start': 720.1, 'duration': 5.359}, {'text': 'in it', 'start': 722.98, 'duration': 2.479}, {'text': \"and we're gonna send in the embed size\", 'start': 726.279, 'duration': 6.36}, {'text': \"and we're also gonna send Dean heads so\", 'start': 729.939, 'duration': 6.27}, {'text': \"as I said we have an embedding and we're\", 'start': 732.639, 'duration': 6.031}, {'text': 'going to split this embedding into', 'start': 736.209, 'duration': 4.261}, {'text': 'different parts I believe I said eight', 'start': 738.67, 'duration': 5.519}, {'text': 'different parts and in that case how', 'start': 740.47, 'duration': 5.94}, {'text': \"many parts we split it is what we're\", 'start': 744.189, 'duration': 7.2}, {'text': 'gonna call heads so if we have for', 'start': 746.41, 'duration': 7.08}, {'text': 'example in bed size 256 and we have', 'start': 751.389, 'duration': 4.05}, {'text': \"heads eight then we're gonna split it\", 'start': 753.49, 'duration': 9.449}, {'text': \"into eight by 32 parts so let's do we're\", 'start': 755.439, 'duration': 9.481}, {'text': 'gonna just call super first self', 'start': 762.939, 'duration': 6.721}, {'text': \"attention and we're gonna do self and\", 'start': 764.92, 'duration': 9.269}, {'text': \"we're gonna do docked dot in it so we're\", 'start': 769.66, 'duration': 7.32}, {'text': 'gonna initialize a prank class and then', 'start': 774.189, 'duration': 4.2}, {'text': \"we're gonna do self dot embed size\", 'start': 776.98, 'duration': 5.669}, {'text': \"equals embed size we're gonna do self\", 'start': 778.389, 'duration': 9.57}, {'text': 'dot heads equals heads and self dot head', 'start': 782.649, 'duration': 10.711}, {'text': 'dimension equals embed size the integer', 'start': 787.959, 'duration': 8.13}, {'text': \"division by heads all right so let's say\", 'start': 793.36, 'duration': 6.51}, {'text': 'that we want to split it we have 256', 'start': 796.089, 'duration': 5.37}, {'text': 'embedding size we want to split it into', 'start': 799.87, 'duration': 3.81}, {'text': 'seven parts then that would not be', 'start': 801.459, 'duration': 4.44}, {'text': \"possible since we can't make an integer\", 'start': 803.68, 'duration': 4.589}, {'text': 'division of that so what we can do is we', 'start': 805.899, 'duration': 4.98}, {'text': 'can throw out an assert we can say', 'start': 808.269, 'duration': 6.3}, {'text': 'assert self dot we can do it like this', 'start': 810.879, 'duration': 9.56}, {'text': 'self dot head dimension times heads', 'start': 814.569, 'duration': 9.221}, {'text': 'equals embed size', 'start': 820.439, 'duration': 11.541}, {'text': \"and if it doesn't we can say embed size\", 'start': 823.79, 'duration': 11.73}, {'text': 'needs to be divisible by heads what', 'start': 831.98, 'duration': 4.47}, {'text': \"we're gonna do then is we're gonna\", 'start': 835.52, 'duration': 2.88}, {'text': \"define the linear layers that we're\", 'start': 836.45, 'duration': 5.73}, {'text': 'gonna send our values keys and queries', 'start': 838.4, 'duration': 7.29}, {'text': 'through so we can do self dot values is', 'start': 842.18, 'duration': 7.35}, {'text': \"and then that linear and it's just going\", 'start': 845.69, 'duration': 5.07}, {'text': \"to take the head dimension and it's\", 'start': 849.53, 'duration': 2.94}, {'text': 'going to map it to the head dimension', 'start': 850.76, 'duration': 5.16}, {'text': \"and we're gonna set by old bias equals\", 'start': 852.47, 'duration': 5.52}, {'text': \"false then we're going to yourself that\", 'start': 855.92, 'duration': 4.77}, {'text': \"keys is equal to n n dot linear I'm\", 'start': 857.99, 'duration': 5.24}, {'text': 'gonna do self that head I mentioned and', 'start': 860.69, 'duration': 6.5}, {'text': 'I guess same thing', 'start': 863.23, 'duration': 7.26}, {'text': 'could I just copy that could have copied', 'start': 867.19, 'duration': 4.02}, {'text': 'it again', 'start': 870.49, 'duration': 4.47}, {'text': 'but anyways queries and then linear self', 'start': 871.21, 'duration': 5.58}, {'text': 'thought', 'start': 874.96, 'duration': 4.98}, {'text': 'dimension to self dot head I mentioned', 'start': 876.79, 'duration': 8.01}, {'text': \"again bias equals false and then we're\", 'start': 879.94, 'duration': 7.71}, {'text': \"gonna do after we concatenate we're\", 'start': 884.8, 'duration': 5.28}, {'text': \"gonna do fully connected out it's gonna\", 'start': 887.65, 'duration': 7.02}, {'text': 'be an inland ear of heads times self dot', 'start': 890.08, 'duration': 7.92}, {'text': 'head dimension and D and then the embed', 'start': 894.67, 'duration': 4.35}, {'text': 'size I guess', 'start': 898.0, 'duration': 3.0}, {'text': \"yeah so we don't have to write it like\", 'start': 899.02, 'duration': 4.41}, {'text': 'that I guess you know since the heads', 'start': 901.0, 'duration': 5.46}, {'text': 'times the self a damaging needs to be', 'start': 903.43, 'duration': 6.24}, {'text': 'equal to the embed size but yeah maybe', 'start': 906.46, 'duration': 5.46}, {'text': 'this makes it a little bit clearer that', 'start': 909.67, 'duration': 4.89}, {'text': \"we're gonna concatenate them and then\", 'start': 911.92, 'duration': 5.72}, {'text': \"we're gonna do the forward\", 'start': 914.56, 'duration': 3.08}, {'text': \"and we're gonna send in the values keys\", 'start': 917.85, 'duration': 5.67}, {'text': \"query and we're also gonna send in a\", 'start': 920.37, 'duration': 5.42}, {'text': 'mask', 'start': 923.52, 'duration': 2.27}, {'text': \"so the first thing we're gonna do is\", 'start': 927.0, 'duration': 2.85}, {'text': \"we're gonna get the number of training\", 'start': 928.529, 'duration': 4.56}, {'text': \"examples so n we're gonna set to query\", 'start': 929.85, 'duration': 7.469}, {'text': \"dot shape of 0 and that's gonna be how\", 'start': 933.089, 'duration': 6.0}, {'text': 'many examples we send in at the same', 'start': 937.319, 'duration': 5.611}, {'text': \"time then we're gonna do the value line\", 'start': 939.089, 'duration': 7.79}, {'text': 'the key length and the query length and', 'start': 942.93, 'duration': 7.199}, {'text': 'remember the value and I guess those', 'start': 946.879, 'duration': 6.221}, {'text': 'length or girth are going to depending', 'start': 950.129, 'duration': 5.07}, {'text': 'on where we use the attention mechanism', 'start': 953.1, 'duration': 5.51}, {'text': 'is going to be be corresponding to the', 'start': 955.199, 'duration': 5.971}, {'text': 'source sentence length and the target', 'start': 958.61, 'duration': 6.269}, {'text': \"sentence length but since we don't know\", 'start': 961.17, 'duration': 6.149}, {'text': 'exactly where this mechanism is used', 'start': 964.879, 'duration': 4.421}, {'text': 'either in the encoder or which part in', 'start': 967.319, 'duration': 4.861}, {'text': 'the decoder those are going to vary so', 'start': 969.3, 'duration': 6.779}, {'text': 'we just use the abstract of saying we', 'start': 972.18, 'duration': 5.79}, {'text': 'just use it abstractly and say value', 'start': 976.079, 'duration': 3.63}, {'text': 'link key length and query length but', 'start': 977.97, 'duration': 3.239}, {'text': 'really they will always correspond to', 'start': 979.709, 'duration': 3.391}, {'text': 'the source sentence length and the', 'start': 981.209, 'duration': 4.32}, {'text': \"target sentence length and that's just\", 'start': 983.1, 'duration': 4.56}, {'text': \"one thing to keep in mind and then we're\", 'start': 985.529, 'duration': 4.43}, {'text': 'just going to values that shape of one', 'start': 987.66, 'duration': 6.51}, {'text': 'keys that shape shape of one and then', 'start': 989.959, 'duration': 7.63}, {'text': \"query shape of one and that's just where\", 'start': 994.17, 'duration': 5.59}, {'text': \"they're going to be\", 'start': 997.589, 'duration': 4.721}, {'text': 'in the in the dimensions so what we want', 'start': 999.76, 'duration': 4.83}, {'text': 'to do now is want to split embedding', 'start': 1002.31, 'duration': 6.3}, {'text': \"into self dot heads pieces so we're\", 'start': 1004.59, 'duration': 8.75}, {'text': 'gonna do values is values dot reshape', 'start': 1008.61, 'duration': 7.649}, {'text': 'reshape', 'start': 1013.34, 'duration': 5.159}, {'text': 'and then we have n comma value Ling', 'start': 1016.259, 'duration': 6.031}, {'text': 'comma self dot heads call myself that', 'start': 1018.499, 'duration': 7.121}, {'text': 'head dimension so these two right here', 'start': 1022.29, 'duration': 5.369}, {'text': \"is where we're splitting it since this\", 'start': 1025.62, 'duration': 4.5}, {'text': 'time this was before a single dimension', 'start': 1027.659, 'duration': 5.28}, {'text': \"of just in bed size now it's going to be\", 'start': 1030.12, 'duration': 4.649}, {'text': 'self that heads and then self that head', 'start': 1032.939, 'duration': 4.14}, {'text': \"dimension and we're gonna do the same\", 'start': 1034.769, 'duration': 5.64}, {'text': 'thing for the keys so key start reshape', 'start': 1037.079, 'duration': 7.531}, {'text': \"we're gonna do n key lengths self\", 'start': 1040.409, 'duration': 6.42}, {'text': 'thought heads and then self dot head', 'start': 1044.61, 'duration': 5.34}, {'text': 'dimension moving along to the queries', 'start': 1046.829, 'duration': 4.621}, {'text': \"we're gonna do pretty much the same\", 'start': 1049.95, 'duration': 6.42}, {'text': 'thing query dot reshape and key length', 'start': 1051.45, 'duration': 9.39}, {'text': 'self dot heads and then self thought', 'start': 1056.37, 'duration': 7.289}, {'text': \"head dimension and then what we're gonna\", 'start': 1060.84, 'duration': 6.839}, {'text': 'do is we want to multiply the queries', 'start': 1063.659, 'duration': 8.49}, {'text': \"with the keys and so we're gonna call\", 'start': 1067.679, 'duration': 8.431}, {'text': \"the output from that energy and what I'm\", 'start': 1072.149, 'duration': 5.611}, {'text': \"gonna use is maybe something that you're\", 'start': 1076.11, 'duration': 3.6}, {'text': \"not familiar with but it's towards that\", 'start': 1077.76, 'duration': 4.5}, {'text': \"in some and I'll explain what it does\", 'start': 1079.71, 'duration': 5.429}, {'text': \"but essentially it's we're gonna use it\", 'start': 1082.26, 'duration': 6.18}, {'text': 'for matrix multiplication where we have', 'start': 1085.139, 'duration': 6.691}, {'text': \"several other dimensions so let's just\", 'start': 1088.44, 'duration': 5.599}, {'text': 'bring out the shapes first we have', 'start': 1091.83, 'duration': 7.799}, {'text': 'queries so queries shape is n comma', 'start': 1094.039, 'duration': 6.52}, {'text': 'query link', 'start': 1099.629, 'duration': 4.621}, {'text': 'come ahead come ahead dimension and then', 'start': 1100.559, 'duration': 6.631}, {'text': 'we have keys shape and I guess pretty', 'start': 1104.25, 'duration': 5.7}, {'text': 'much the same and comma key lang heads', 'start': 1107.19, 'duration': 7.949}, {'text': 'heads dimension and so what we want so', 'start': 1109.95, 'duration': 11.4}, {'text': 'we energy is gonna be n comma heads', 'start': 1115.139, 'duration': 10.53}, {'text': 'comma query length comma key length all', 'start': 1121.35, 'duration': 6.419}, {'text': 'right so you know you can kind of view', 'start': 1125.669, 'duration': 5.041}, {'text': \"this as you know let's say that the\", 'start': 1127.769, 'duration': 6.481}, {'text': 'query length is the is it is the target', 'start': 1130.71, 'duration': 7.76}, {'text': 'source sentence and the key length is is', 'start': 1134.25, 'duration': 6.59}, {'text': 'there', 'start': 1138.47, 'duration': 4.92}, {'text': 'is the source sentence then this will', 'start': 1140.84, 'duration': 4.74}, {'text': 'kind of say that okay for each word in', 'start': 1143.39, 'duration': 4.11}, {'text': 'our target how much should we pay', 'start': 1145.58, 'duration': 5.37}, {'text': 'attention to each word in our input in', 'start': 1147.5, 'duration': 8.159}, {'text': 'the store sentence and what we want here', 'start': 1150.95, 'duration': 6.42}, {'text': 'anyways for the matrix multiplication is', 'start': 1155.659, 'duration': 4.861}, {'text': 'that we want to multiply well actually', 'start': 1157.37, 'duration': 8.419}, {'text': \"let's do this first so right see right\", 'start': 1160.52, 'duration': 8.269}, {'text': 'here', 'start': 1165.789, 'duration': 3.0}, {'text': \"we're gonna do n query for the query\", 'start': 1169.39, 'duration': 7.57}, {'text': 'length H for the heads and then D for', 'start': 1173.96, 'duration': 6.39}, {'text': \"the heads dimension and then we're gonna\", 'start': 1176.96, 'duration': 7.74}, {'text': 'do comma N K again for the key key', 'start': 1180.35, 'duration': 7.89}, {'text': 'length n for the batch size key K for', 'start': 1184.7, 'duration': 5.94}, {'text': 'the Kaling and then age for the heads', 'start': 1188.24, 'duration': 4.38}, {'text': 'and then D for the head dimension and', 'start': 1190.64, 'duration': 4.919}, {'text': \"then we're gonna create a let's see if I\", 'start': 1192.62, 'duration': 6.21}, {'text': \"can do this we're gonna do in an arrow\", 'start': 1195.559, 'duration': 8.25}, {'text': 'like like this no not like that like', 'start': 1198.83, 'duration': 9.96}, {'text': \"this and then we're gonna specify the\", 'start': 1203.809, 'duration': 7.681}, {'text': 'output shape so we still want n to be', 'start': 1208.79, 'duration': 5.04}, {'text': 'the output shape and then we want head', 'start': 1211.49, 'duration': 4.41}, {'text': 'to be the first one and then we want', 'start': 1213.83, 'duration': 5.13}, {'text': 'query length and then we want key length', 'start': 1215.9, 'duration': 6.93}, {'text': 'all right this is um has quickly become', 'start': 1218.96, 'duration': 7.32}, {'text': 'sort of my favorite notation instead of', 'start': 1222.83, 'duration': 6.39}, {'text': 'using major to multiply or you know in', 'start': 1226.28, 'duration': 4.47}, {'text': 'this case what you would have to do is', 'start': 1229.22, 'duration': 3.66}, {'text': 'you would have to use batch matrix', 'start': 1230.75, 'duration': 4.77}, {'text': 'multiply since we have a batch here and', 'start': 1232.88, 'duration': 4.71}, {'text': 'you would even have to do it a little', 'start': 1235.52, 'duration': 4.289}, {'text': 'bit more complicated since we have this', 'start': 1237.59, 'duration': 4.74}, {'text': 'additional dimension here for their', 'start': 1239.809, 'duration': 4.771}, {'text': 'heads you would first have to flatten', 'start': 1242.33, 'duration': 4.74}, {'text': 'the the training examples with the heads', 'start': 1244.58, 'duration': 6.15}, {'text': 'and then use torch that batch matrix', 'start': 1247.07, 'duration': 7.38}, {'text': 'multiply so you would have to use torch', 'start': 1250.73, 'duration': 7.65}, {'text': \"dot B mmm but you know if you don't want\", 'start': 1254.45, 'duration': 7.47}, {'text': 'to remember sort of those syntax for how', 'start': 1258.38, 'duration': 5.7}, {'text': 'to do that you can just use n some and', 'start': 1261.92, 'duration': 6.21}, {'text': \"it's going to be super easy and what we\", 'start': 1264.08, 'duration': 5.46}, {'text': 'have to do here as well is that we need', 'start': 1268.13, 'duration': 5.73}, {'text': 'to send in the queries and then the keys', 'start': 1269.54, 'duration': 9.6}, {'text': \"and that's it we're gonna add a mask now\", 'start': 1273.86, 'duration': 8.16}, {'text': \"so we're gonna do if mask is not none so\", 'start': 1279.14, 'duration': 4.2}, {'text': 'if we send in a mask', 'start': 1282.02, 'duration': 4.46}, {'text': \"then we're gonna do energy equals energy\", 'start': 1283.34, 'duration': 7.44}, {'text': 'dot masked underscore fill and then', 'start': 1286.48, 'duration': 6.19}, {'text': \"we're gonna do mask equals equals zero\", 'start': 1290.78, 'duration': 5.279}, {'text': 'so essentially if the element of the', 'start': 1292.67, 'duration': 5.4}, {'text': 'mask is zero then that means that we', 'start': 1296.059, 'duration': 5.311}, {'text': 'want to shut that shut that off so that', 'start': 1298.07, 'duration': 7.71}, {'text': \"it doesn't impact any other I guess yeah\", 'start': 1301.37, 'duration': 7.86}, {'text': 'so essentially you know as we saw', 'start': 1305.78, 'duration': 6.51}, {'text': 'previously the the mask for the for the', 'start': 1309.23, 'duration': 7.37}, {'text': 'target is gonna be a triangular matrix', 'start': 1312.29, 'duration': 6.81}, {'text': \"but we're gonna define that later on but\", 'start': 1316.6, 'duration': 5.41}, {'text': 'anyways the element that you know when', 'start': 1319.1, 'duration': 6.93}, {'text': \"we're gonna close it is zero and what it\", 'start': 1322.01, 'duration': 5.52}, {'text': \"means to close it is that we're gonna\", 'start': 1326.03, 'duration': 5.54}, {'text': 'replace those elements with a float', 'start': 1327.53, 'duration': 6.24}, {'text': \"where it's we're gonna set it to\", 'start': 1331.57, 'duration': 4.81}, {'text': 'essentially minus infinity but just for', 'start': 1333.77, 'duration': 5.49}, {'text': \"numerical so it doesn't bring any\", 'start': 1336.38, 'duration': 5.549}, {'text': 'numerical under overflowed anything like', 'start': 1339.26, 'duration': 5.73}, {'text': 'that we want it just to set it to a very', 'start': 1341.929, 'duration': 6.0}, {'text': \"very small value and so let's see what's\", 'start': 1344.99, 'duration': 7.669}, {'text': 'going to happen is you know', 'start': 1347.929, 'duration': 7.07}, {'text': 'run this through south max now so when', 'start': 1352.659, 'duration': 4.26}, {'text': 'we have those essentially minus infinity', 'start': 1354.999, 'duration': 5.04}, {'text': \"then they're going to be you know set to\", 'start': 1356.919, 'duration': 6.33}, {'text': \"zero so we're going to do a tension now\", 'start': 1360.039, 'duration': 6.45}, {'text': \"and we're gonna do torch that softmax\", 'start': 1363.249, 'duration': 6.3}, {'text': \"and we're gonna do energy and then we're\", 'start': 1366.489, 'duration': 6.0}, {'text': 'also going to divide it with the embed', 'start': 1369.549, 'duration': 5.01}, {'text': 'size or the square root of the embed', 'start': 1372.489, 'duration': 4.94}, {'text': 'size just for that numerical stability', 'start': 1374.559, 'duration': 6.24}, {'text': \"so we're gonna do raise to 1/2 and then\", 'start': 1377.429, 'duration': 7.06}, {'text': \"we're gonna do dimension equals 3 and\", 'start': 1380.799, 'duration': 6.09}, {'text': \"this means that we're normalizing across\", 'start': 1384.489, 'duration': 6.42}, {'text': 'the key length which for example would', 'start': 1386.889, 'duration': 7.38}, {'text': 'be depending on again where we use the', 'start': 1390.909, 'duration': 6.57}, {'text': \"attention mechanism it's going to let's\", 'start': 1394.269, 'duration': 4.65}, {'text': 'say this is the source sentence and this', 'start': 1397.479, 'duration': 3.78}, {'text': 'is the target sentence length then that', 'start': 1398.919, 'duration': 4.94}, {'text': 'would say you know how much we want to', 'start': 1401.259, 'duration': 4.711}, {'text': \"essentially we're making the attention\", 'start': 1403.859, 'duration': 4.12}, {'text': 'scores normalized to one across the', 'start': 1405.97, 'duration': 4.62}, {'text': 'source sentence so that we if the first', 'start': 1407.979, 'duration': 3.93}, {'text': 'for example is 0.8', 'start': 1410.59, 'duration': 3.24}, {'text': \"that means we're paying 80% attention to\", 'start': 1411.909, 'duration': 4.19}, {'text': 'the first word in the source sentence', 'start': 1413.83, 'duration': 5.039}, {'text': \"what we can do then is out and we're\", 'start': 1416.099, 'duration': 4.841}, {'text': 'gonna now want to multiply the attention', 'start': 1418.869, 'duration': 5.101}, {'text': \"with the values so again we're gonna use\", 'start': 1420.94, 'duration': 5.01}, {'text': 'them my favorite notation find some and', 'start': 1423.97, 'duration': 5.759}, {'text': \"we're gonna do that by C let's bring out\", 'start': 1425.95, 'duration': 5.819}, {'text': 'the shapes first so we have attention', 'start': 1429.729, 'duration': 6.721}, {'text': 'shape we have n comma heads comma query', 'start': 1431.769, 'duration': 7.86}, {'text': 'link comma key length and then we have', 'start': 1436.45, 'duration': 6.689}, {'text': \"the values of shape and we're gonna have\", 'start': 1439.629, 'duration': 8.941}, {'text': 'n comma value length heads and then', 'start': 1443.139, 'duration': 9.84}, {'text': 'heads dimension and what we want the', 'start': 1448.57, 'duration': 7.049}, {'text': 'after the matrix multiply is we want it', 'start': 1452.979, 'duration': 7.94}, {'text': 'to be n comma query length comma heads', 'start': 1455.619, 'duration': 8.94}, {'text': \"comma head dimension all right that's so\", 'start': 1460.919, 'duration': 8.051}, {'text': 'what we want here is the key key length', 'start': 1464.559, 'duration': 5.761}, {'text': 'and the value lengths are always going', 'start': 1468.97, 'duration': 3.52}, {'text': 'to be the same', 'start': 1470.32, 'duration': 5.41}, {'text': 'if you just check how we are sending it', 'start': 1472.49, 'duration': 5.22}, {'text': 'in you know in the encoder they are all', 'start': 1475.73, 'duration': 3.98}, {'text': 'going to be the same obviously the the', 'start': 1477.71, 'duration': 4.56}, {'text': \"it's just going to be the same input\", 'start': 1479.71, 'duration': 4.21}, {'text': \"we're gonna see that later on as well\", 'start': 1482.27, 'duration': 4.02}, {'text': 'but the value and the key lengths are', 'start': 1483.92, 'duration': 5.49}, {'text': 'always going to be the same value so', 'start': 1486.29, 'duration': 5.7}, {'text': \"we're gonna multiply across that\", 'start': 1489.41, 'duration': 9.53}, {'text': 'dimension so again we can we can do', 'start': 1491.99, 'duration': 6.95}, {'text': \"see you can do this right here and we're\", 'start': 1498.98, 'duration': 6.0}, {'text': 'gonna call it n for the batch size for', 'start': 1501.74, 'duration': 6.98}, {'text': 'the attention and then heads and then', 'start': 1504.98, 'duration': 7.05}, {'text': \"query lengths and then we're just gonna\", 'start': 1508.72, 'duration': 5.56}, {'text': 'call it L for the for the dimension that', 'start': 1512.03, 'duration': 4.19}, {'text': 'we want to multiply across', 'start': 1514.28, 'duration': 5.76}, {'text': \"then we're gonna do again n comma I\", 'start': 1516.22, 'duration': 7.839}, {'text': \"guess n L so that's gonna be for the\", 'start': 1520.04, 'duration': 6.09}, {'text': 'value length and since the key length', 'start': 1524.059, 'duration': 4.591}, {'text': 'and value of match now so both are L', 'start': 1526.13, 'duration': 5.7}, {'text': \"then we're going to do H and then we're\", 'start': 1528.65, 'duration': 6.03}, {'text': 'going to do D', 'start': 1531.83, 'duration': 5.34}, {'text': \"and we're going to map this let's see\", 'start': 1534.68, 'duration': 5.55}, {'text': \"we're gonna do like this and we're gonna\", 'start': 1537.17, 'duration': 7.05}, {'text': 'do it to N and then the quarreling heads', 'start': 1540.23, 'duration': 6.96}, {'text': 'and then the dimension and magically you', 'start': 1544.22, 'duration': 4.65}, {'text': \"know I mean somebody's gonna know what\", 'start': 1547.19, 'duration': 4.64}, {'text': 'to do with that so', 'start': 1548.87, 'duration': 2.96}, {'text': \"all we're going to do then is just do\", 'start': 1552.29, 'duration': 5.55}, {'text': 'the attention and sending the values', 'start': 1554.3, 'duration': 8.16}, {'text': \"and also so we're now gonna want to do\", 'start': 1557.84, 'duration': 8.48}, {'text': 'the concatenation part so we can do that', 'start': 1562.46, 'duration': 7.29}, {'text': 'we can do that instantly after this tour', 'start': 1566.32, 'duration': 6.04}, {'text': 'shot eins on so we can do dark reshape', 'start': 1569.75, 'duration': 6.48}, {'text': 'and we can do n comma query link and', 'start': 1572.36, 'duration': 7.32}, {'text': 'then we can just self that heads x self', 'start': 1576.23, 'duration': 6.48}, {'text': \"dot head dimension so we're just\", 'start': 1579.68, 'duration': 8.49}, {'text': 'concatenated us so we can do and we can', 'start': 1582.71, 'duration': 11.46}, {'text': 'write it here after eins um then we can', 'start': 1588.17, 'duration': 10.97}, {'text': 'just do then flatten last two dimensions', 'start': 1594.17, 'duration': 8.55}, {'text': 'something like that and what we want to', 'start': 1599.14, 'duration': 7.48}, {'text': 'do lastly is just send it through FC out', 'start': 1602.72, 'duration': 5.55}, {'text': \"so we're just going to do that and we're\", 'start': 1606.62, 'duration': 4.2}, {'text': 'going to return out and this FC out', 'start': 1608.27, 'duration': 5.1}, {'text': \"won't change the dimension since the FC\", 'start': 1610.82, 'duration': 6.24}, {'text': 'FC out just Maps the embed size to embed', 'start': 1613.37, 'duration': 8.46}, {'text': 'size alright so now that we have the', 'start': 1617.06, 'duration': 6.96}, {'text': 'attention this is gonna be a lot easier', 'start': 1621.83, 'duration': 4.1}, {'text': \"for us so we're just gonna create the\", 'start': 1624.02, 'duration': 4.77}, {'text': \"you know now we're gonna let's see we're\", 'start': 1625.93, 'duration': 5.35}, {'text': \"gonna create the transformer block we're\", 'start': 1628.79, 'duration': 5.28}, {'text': 'just going to class transformer block', 'start': 1631.28, 'duration': 4.44}, {'text': \"and we're going to end in module\", 'start': 1634.07, 'duration': 3.7}, {'text': '[Music]', 'start': 1635.72, 'duration': 5.02}, {'text': \"I'm going to define in it and we're\", 'start': 1637.77, 'duration': 5.96}, {'text': 'going to do the embed size', 'start': 1640.74, 'duration': 2.99}, {'text': \"I'm gonna send in the embed size the\", 'start': 1643.76, 'duration': 5.039}, {'text': \"heads drop out and we're also going to\", 'start': 1645.74, 'duration': 4.47}, {'text': 'send in something called forward', 'start': 1648.799, 'duration': 3.181}, {'text': \"expansion and I'm going to talk about\", 'start': 1650.21, 'duration': 5.4}, {'text': \"that when we use it so we're gonna super\", 'start': 1651.98, 'duration': 6.659}, {'text': \"and we're gonna do transform a block and\", 'start': 1655.61, 'duration': 9.14}, {'text': \"we're gonna do self and then see thought\", 'start': 1658.639, 'duration': 8.951}, {'text': 'in it', 'start': 1664.75, 'duration': 2.84}, {'text': \"and we're going to do self that\", 'start': 1667.75, 'duration': 5.4}, {'text': 'attention is equal to self attention of', 'start': 1669.52, 'duration': 6.39}, {'text': 'embed size and heads', 'start': 1673.15, 'duration': 4.7}, {'text': \"so essentially you know we're using that\", 'start': 1675.91, 'duration': 6.47}, {'text': 'attention that we implemented above', 'start': 1677.85, 'duration': 4.53}, {'text': \"and then we're gonna do the so then the\", 'start': 1683.05, 'duration': 7.56}, {'text': \"normal normalization so we're gonna do\", 'start': 1687.94, 'duration': 5.04}, {'text': 'self that norm one is going to be', 'start': 1690.61, 'duration': 4.92}, {'text': \"because we're gonna use to normalize it\", 'start': 1692.98, 'duration': 3.72}, {'text': \"and we're first gonna send it through a\", 'start': 1695.53, 'duration': 4.35}, {'text': 'normalization a attention block then', 'start': 1696.7, 'duration': 4.26}, {'text': 'going to send it to a normalization', 'start': 1699.88, 'duration': 3.09}, {'text': \"we're gonna send to a feed-forward and\", 'start': 1700.96, 'duration': 2.91}, {'text': \"then we're going to send it to another\", 'start': 1702.97, 'duration': 3.39}, {'text': 'normalization', 'start': 1703.87, 'duration': 6.27}, {'text': 'so we can do a layer norm of embed size', 'start': 1706.36, 'duration': 8.189}, {'text': 'and layer norm again one of those', 'start': 1710.14, 'duration': 6.87}, {'text': \"details so if you're familiar with with\", 'start': 1714.549, 'duration': 5.581}, {'text': 'batch norm what that is Lane room and', 'start': 1717.01, 'duration': 4.649}, {'text': 'bathroom are very similar except that', 'start': 1720.13, 'duration': 4.44}, {'text': 'batch norm takes the average across the', 'start': 1721.659, 'duration': 5.431}, {'text': 'batch and then normalizes whereas layer', 'start': 1724.57, 'duration': 4.92}, {'text': 'norm just takes an average for every', 'start': 1727.09, 'duration': 4.709}, {'text': 'single example', 'start': 1729.49, 'duration': 4.289}, {'text': 'so I guess layin worm has more', 'start': 1731.799, 'duration': 4.74}, {'text': 'computation than Bachelor but', 'start': 1733.779, 'duration': 4.681}, {'text': 'essentially it uses the same formula it', 'start': 1736.539, 'duration': 5.52}, {'text': 'just does it per example rather than for', 'start': 1738.46, 'duration': 7.11}, {'text': \"the batch so then we're going to do\", 'start': 1742.059, 'duration': 5.761}, {'text': \"another one self dot norm - it's going\", 'start': 1745.57, 'duration': 5.04}, {'text': 'to be a nun layer norm of again the', 'start': 1747.82, 'duration': 6.449}, {'text': 'embed size and then the feed forward', 'start': 1750.61, 'duration': 5.37}, {'text': \"part of the transformer block we're\", 'start': 1754.269, 'duration': 4.231}, {'text': \"going to do self dot feed-forward it's\", 'start': 1755.98, 'duration': 5.13}, {'text': \"gonna be a nun dot sequential so we're\", 'start': 1758.5, 'duration': 4.47}, {'text': 'going to use a different a nun linear', 'start': 1761.11, 'duration': 3.75}, {'text': \"here and what we can do is we're going\", 'start': 1762.97, 'duration': 4.38}, {'text': 'to do any linear for from the embed size', 'start': 1764.86, 'duration': 6.09}, {'text': \"as input and then we're going to map it\", 'start': 1767.35, 'duration': 7.89}, {'text': 'to forward expansion times the embed', 'start': 1770.95, 'duration': 7.79}, {'text': \"size so essentially you know we're\", 'start': 1775.24, 'duration': 6.51}, {'text': 'mapping it to some more nodes which is', 'start': 1778.74, 'duration': 5.89}, {'text': 'dependent on the forward expansion so in', 'start': 1781.75, 'duration': 4.769}, {'text': 'the paper they use forward expansion to', 'start': 1784.63, 'duration': 4.2}, {'text': \"four so it'll they have them embed size\", 'start': 1786.519, 'duration': 4.41}, {'text': 'and then it just times that by 4 which', 'start': 1788.83, 'duration': 4.589}, {'text': 'is the intermediate number of nodes they', 'start': 1790.929, 'duration': 6.12}, {'text': 'do an NN relu I really like this and', 'start': 1793.419, 'duration': 6.74}, {'text': 'then they use another nonlinear and', 'start': 1797.049, 'duration': 6.23}, {'text': \"they're gonna do the forward expansion\", 'start': 1800.159, 'duration': 5.801}, {'text': \"times the embed size and you're just\", 'start': 1803.279, 'duration': 5.02}, {'text': 'gonna map it back to the embed size so', 'start': 1805.96, 'duration': 4.62}, {'text': 'you know the this feed-forward block is', 'start': 1808.299, 'duration': 4.201}, {'text': \"not really changing anything it's just\", 'start': 1810.58, 'duration': 5.28}, {'text': 'doing some extra computation and then', 'start': 1812.5, 'duration': 5.769}, {'text': 'mapping it back', 'start': 1815.86, 'duration': 6.159}, {'text': 'and then lastly we want to do self dot', 'start': 1818.269, 'duration': 8.58}, {'text': 'drop out well self dot drop out is equal', 'start': 1822.019, 'duration': 8.841}, {'text': 'to n n dot drop out of drop out', 'start': 1826.849, 'duration': 7.491}, {'text': 'and for our forward see if I can make', 'start': 1830.86, 'duration': 5.31}, {'text': 'this a little bit more centered all', 'start': 1834.34, 'duration': 3.63}, {'text': 'right so now we can scroll past the', 'start': 1836.17, 'duration': 4.92}, {'text': \"bottom alright so we're gonna do the\", 'start': 1837.97, 'duration': 5.13}, {'text': \"forward and we're gonna send in you know\", 'start': 1841.09, 'duration': 4.32}, {'text': \"the value the key the query and we're\", 'start': 1843.1, 'duration': 5.82}, {'text': \"also going to send in a mask then we're\", 'start': 1845.41, 'duration': 5.67}, {'text': 'going to do attention equals self dot', 'start': 1848.92, 'duration': 4.2}, {'text': \"attention and we're just going to send\", 'start': 1851.08, 'duration': 4.17}, {'text': 'them the value key the query and the', 'start': 1853.12, 'duration': 6.02}, {'text': \"mask and then you know we're gonna do\", 'start': 1855.25, 'duration': 7.41}, {'text': 'self dot norm one and one thing to', 'start': 1859.14, 'duration': 6.159}, {'text': \"remember is that we're gonna send in a\", 'start': 1862.66, 'duration': 4.95}, {'text': \"skip connection and that's going to be\", 'start': 1865.299, 'duration': 4.831}, {'text': 'the attention that we just computed and', 'start': 1867.61, 'duration': 6.3}, {'text': \"we're gonna add it with the query so\", 'start': 1870.13, 'duration': 7.02}, {'text': \"that's the skip connection then we're\", 'start': 1873.91, 'duration': 6.95}, {'text': 'going to do self dot drop out', 'start': 1877.15, 'duration': 3.71}, {'text': 'see', 'start': 1882.38, 'duration': 6.21}, {'text': \"like this and we're gonna do x equals\", 'start': 1884.75, 'duration': 7.77}, {'text': \"that then we're going to do forward\", 'start': 1888.59, 'duration': 8.9}, {'text': 'equals self dot feed-forward of of X and', 'start': 1892.52, 'duration': 9.27}, {'text': \"then we're gonna do out equals self dot\", 'start': 1897.49, 'duration': 7.39}, {'text': \"let's you suffer drop out of self dot\", 'start': 1901.79, 'duration': 5.31}, {'text': \"norm two and again we're gonna add the\", 'start': 1904.88, 'duration': 3.39}, {'text': \"skipped connection so we're going to do\", 'start': 1907.1, 'duration': 4.25}, {'text': \"forward but we're also going to add the\", 'start': 1908.27, 'duration': 8.0}, {'text': 'the X from the after the norm norm one', 'start': 1911.35, 'duration': 8.34}, {'text': \"then we're just going to return out and\", 'start': 1916.27, 'duration': 7.45}, {'text': \"that's the transformer block so as I\", 'start': 1919.69, 'duration': 6.99}, {'text': 'said the attention part right here is', 'start': 1923.72, 'duration': 5.91}, {'text': 'really the most difficult part the', 'start': 1926.68, 'duration': 4.54}, {'text': 'transformer block is pretty easy and now', 'start': 1929.63, 'duration': 4.11}, {'text': \"we're just gonna try to stick this\", 'start': 1931.22, 'duration': 5.1}, {'text': 'together and form the encoder and the', 'start': 1933.74, 'duration': 5.34}, {'text': \"decoder so we're going to do class\", 'start': 1936.32, 'duration': 6.75}, {'text': \"encoder we're going to do any module and\", 'start': 1939.08, 'duration': 7.08}, {'text': \"we're gonna do define in it and we're\", 'start': 1943.07, 'duration': 6.74}, {'text': \"gonna let's see we're gonna do a self\", 'start': 1946.16, 'duration': 7.77}, {'text': \"we're gonna send in the source vocab\", 'start': 1949.81, 'duration': 5.99}, {'text': 'size', 'start': 1953.93, 'duration': 3.52}, {'text': \"because remember now what we're gonna do\", 'start': 1955.8, 'duration': 3.51}, {'text': \"is we're gonna do the embedding and all\", 'start': 1957.45, 'duration': 3.87}, {'text': \"of those things as well and we're also\", 'start': 1959.31, 'duration': 4.83}, {'text': 'gonna use the transformer block for a', 'start': 1961.32, 'duration': 5.31}, {'text': \"couple of layers so we're gonna send in\", 'start': 1964.14, 'duration': 6.72}, {'text': \"the embed size we're gonna send in the\", 'start': 1966.63, 'duration': 6.78}, {'text': \"number of layers we're gonna send in\", 'start': 1970.86, 'duration': 3.36}, {'text': 'heads', 'start': 1973.41, 'duration': 2.97}, {'text': \"we're gonna send in the device we're\", 'start': 1974.22, 'duration': 4.32}, {'text': 'gonna send in forward expansion all', 'start': 1976.38, 'duration': 3.63}, {'text': 'right all of these are hyper parameters', 'start': 1978.54, 'duration': 3.69}, {'text': \"of our model we're sending the drop out\", 'start': 1980.01, 'duration': 4.11}, {'text': \"and we're gonna send in something called\", 'start': 1982.23, 'duration': 7.92}, {'text': \"max length and so first thing we're\", 'start': 1984.12, 'duration': 11.21}, {'text': 'gonna call a super of encoder self dot', 'start': 1990.15, 'duration': 8.39}, {'text': 'in it', 'start': 1995.33, 'duration': 3.21}, {'text': \"sighs equals embed size and I'll cover\", 'start': 2000.02, 'duration': 7.35}, {'text': \"let's see so I guess the only thing that\", 'start': 2003.44, 'duration': 5.01}, {'text': \"we haven't talked about this is max\", 'start': 2007.37, 'duration': 4.23}, {'text': 'length and this is related to the', 'start': 2008.45, 'duration': 5.82}, {'text': 'positional embedding so essentially', 'start': 2011.6, 'duration': 5.01}, {'text': \"we're gonna use a positional embedding\", 'start': 2014.27, 'duration': 4.47}, {'text': \"and I'm gonna talk more about that when\", 'start': 2016.61, 'duration': 6.12}, {'text': 'we code that one but essentially the', 'start': 2018.74, 'duration': 5.16}, {'text': 'positional embedding is depending on', 'start': 2022.73, 'duration': 3.8}, {'text': 'position right and so we need to send in', 'start': 2023.9, 'duration': 6.18}, {'text': 'how long is the is the max sentence', 'start': 2026.53, 'duration': 7.06}, {'text': \"length so let's say that we have a\", 'start': 2030.08, 'duration': 5.55}, {'text': 'couple of sentences there are you know', 'start': 2033.59, 'duration': 3.36}, {'text': \"let's say that they are extremely long\", 'start': 2035.63, 'duration': 3.99}, {'text': \"let's say all of our data set is fifty\", 'start': 2036.95, 'duration': 4.5}, {'text': 'in length and then we have a couple of', 'start': 2039.62, 'duration': 3.93}, {'text': 'examples there are a thousand then what', 'start': 2041.45, 'duration': 3.75}, {'text': 'would you would have to do is delete', 'start': 2043.55, 'duration': 3.42}, {'text': 'those that are a thousand and just keep', 'start': 2045.2, 'duration': 4.38}, {'text': 'the ones so that we have sort of a', 'start': 2046.97, 'duration': 6.449}, {'text': 'normal size of our of our data and so', 'start': 2049.58, 'duration': 5.73}, {'text': 'max line could be various depending on', 'start': 2053.419, 'duration': 5.76}, {'text': \"data but perhaps it's like a hundred or\", 'start': 2055.31, 'duration': 5.25}, {'text': 'something like that depending on the', 'start': 2059.179, 'duration': 3.331}, {'text': 'data set', 'start': 2060.56, 'duration': 4.14}, {'text': \"so we're just going to do stuff to embed\", 'start': 2062.51, 'duration': 3.54}, {'text': \"size we're going to set that device\", 'start': 2064.7, 'duration': 4.979}, {'text': \"equals device self dot word I'm betting\", 'start': 2066.05, 'duration': 6.119}, {'text': \"it's going to be n n dot M embedding\", 'start': 2069.679, 'duration': 4.621}, {'text': \"we're gonna send you the source vocab\", 'start': 2072.169, 'duration': 4.021}, {'text': \"size and we're gonna map it to embed\", 'start': 2074.3, 'duration': 3.66}, {'text': 'size', 'start': 2076.19, 'duration': 3.0}, {'text': \"and then we're going to do the\", 'start': 2077.96, 'duration': 3.719}, {'text': 'positional embedding and this is just', 'start': 2079.19, 'duration': 4.679}, {'text': \"going to be n n dot embedding and it's\", 'start': 2081.679, 'duration': 5.371}, {'text': \"it's gonna be max length to embed size\", 'start': 2083.869, 'duration': 4.921}, {'text': 'all right so this is where we use the', 'start': 2087.05, 'duration': 5.579}, {'text': \"max length then we're gonna do self dot\", 'start': 2088.79, 'duration': 5.97}, {'text': \"layers it's gonna be N and that module\", 'start': 2092.629, 'duration': 5.161}, {'text': \"list we're just going to use that to map\", 'start': 2094.76, 'duration': 9.15}, {'text': 'several different different modules', 'start': 2097.79, 'duration': 7.559}, {'text': 'together and those modules are going to', 'start': 2103.91, 'duration': 3.57}, {'text': \"be the transformer block so we're going\", 'start': 2105.349, 'duration': 3.601}, {'text': \"to do transformer block and we're gonna\", 'start': 2107.48, 'duration': 3.96}, {'text': \"send in the embed size we're gonna send\", 'start': 2108.95, 'duration': 5.07}, {'text': \"in heads we're gonna send them drop out\", 'start': 2111.44, 'duration': 5.01}, {'text': \"equals drop out we're gonna send in\", 'start': 2114.02, 'duration': 5.52}, {'text': 'forward expansion forward expansion', 'start': 2116.45, 'duration': 8.88}, {'text': \"equals forward expansion and that's it\", 'start': 2119.54, 'duration': 7.68}, {'text': \"for the number of layers let's scroll\", 'start': 2125.33, 'duration': 5.519}, {'text': \"down again and then we're just gonna do\", 'start': 2127.22, 'duration': 7.59}, {'text': 'self dot drop out equals and then drop', 'start': 2130.849, 'duration': 6.521}, {'text': 'out of drop out', 'start': 2134.81, 'duration': 4.69}, {'text': 'all right so where do the four parts', 'start': 2137.37, 'duration': 4.77}, {'text': \"we're gonna be forward self we're gonna\", 'start': 2139.5, 'duration': 7.23}, {'text': 'send in just one input to the to the', 'start': 2142.14, 'duration': 8.97}, {'text': 'forward and we can also going to send in', 'start': 2146.73, 'duration': 6.68}, {'text': 'a mask', 'start': 2151.11, 'duration': 4.13}, {'text': \"then we're just gonna do n comma\", 'start': 2153.41, 'duration': 6.21}, {'text': \"sequence length is X out shape so that's\", 'start': 2155.24, 'duration': 6.03}, {'text': \"that's all we have from the beginning\", 'start': 2159.62, 'duration': 3.66}, {'text': 'right we have an example sent in and we', 'start': 2161.27, 'duration': 5.47}, {'text': 'have some some sequence length', 'start': 2163.28, 'duration': 5.55}, {'text': 'and', 'start': 2166.74, 'duration': 2.09}, {'text': \"just going to do first of all we're just\", 'start': 2169.6, 'duration': 4.53}, {'text': \"going to do positions that we're gonna\", 'start': 2171.25, 'duration': 7.91}, {'text': 'do torture arranged 0 to sequence length', 'start': 2174.13, 'duration': 7.71}, {'text': \"and then we're gonna do dot expand and\", 'start': 2179.16, 'duration': 5.44}, {'text': 'comma sequence length so that we have', 'start': 2181.84, 'duration': 3.87}, {'text': 'sequence', 'start': 2184.6, 'duration': 4.62}, {'text': 'guess arranged so 0 1 2 3 etc up to', 'start': 2185.71, 'duration': 5.69}, {'text': 'sequence length for every example and', 'start': 2189.22, 'duration': 6.12}, {'text': \"then we're just gonna do dot to self dot\", 'start': 2191.4, 'duration': 8.95}, {'text': \"device and then we're gonna send through\", 'start': 2195.34, 'duration': 7.86}, {'text': \"X through an embedding and we're just\", 'start': 2200.35, 'duration': 4.5}, {'text': \"gonna and we're also gonna add a\", 'start': 2203.2, 'duration': 3.84}, {'text': 'positional embedding so self that word', 'start': 2204.85, 'duration': 6.27}, {'text': 'embedding of X plus self top position', 'start': 2207.04, 'duration': 9.96}, {'text': 'embedding of positions and this together', 'start': 2211.12, 'duration': 8.25}, {'text': 'is then going to be sent in through drop', 'start': 2217.0, 'duration': 5.01}, {'text': \"and drop out so we're just gonna do\", 'start': 2219.37, 'duration': 5.97}, {'text': \"something like that and we're gonna do\", 'start': 2222.01, 'duration': 6.35}, {'text': 'out equal static', 'start': 2225.34, 'duration': 4.91}, {'text': 'and so you know if you really think', 'start': 2228.36, 'duration': 4.22}, {'text': 'about it the only thing that makes it', 'start': 2230.25, 'duration': 5.28}, {'text': 'aware of the positions is this thing', 'start': 2232.58, 'duration': 5.41}, {'text': \"right here we're all we're gonna send in\", 'start': 2235.53, 'duration': 5.37}, {'text': 'is the positions which is just 0 1 2 3', 'start': 2237.99, 'duration': 7.32}, {'text': 'etc and magically this learns how to how', 'start': 2240.9, 'duration': 9.78}, {'text': 'to you know how words are structured in', 'start': 2245.31, 'duration': 7.53}, {'text': 'in you know the permutation of the words', 'start': 2250.68, 'duration': 5.1}, {'text': 'I find that a little bit magical that', 'start': 2252.84, 'duration': 7.68}, {'text': 'that actually word works but anyways so', 'start': 2255.78, 'duration': 5.94}, {'text': \"we're gonna do for a layer in\", 'start': 2260.52, 'duration': 4.41}, {'text': \"self-taught layers we're gonna do out\", 'start': 2261.72, 'duration': 8.76}, {'text': 'equals layer of this is gonna be a', 'start': 2264.93, 'duration': 7.41}, {'text': 'little bit word but since we are in the', 'start': 2270.48, 'duration': 5.55}, {'text': \"encoder the let's see its value key and\", 'start': 2272.34, 'duration': 7.44}, {'text': 'the what is the value key inquiry are', 'start': 2276.03, 'duration': 5.34}, {'text': \"all gonna be the same so we're just\", 'start': 2279.78, 'duration': 6.0}, {'text': 'gonna send in out out out I was sending', 'start': 2281.37, 'duration': 7.62}, {'text': \"the mask all right so that's looks a bit\", 'start': 2285.78, 'duration': 7.02}, {'text': \"odd but that's just the special case in\", 'start': 2288.99, 'duration': 6.06}, {'text': 'the in this scenario in the encoder all', 'start': 2292.8, 'duration': 3.75}, {'text': 'of the inputs are going to be the same', 'start': 2295.05, 'duration': 5.97}, {'text': \"so and then we're gonna do return out\", 'start': 2296.55, 'duration': 6.48}, {'text': 'all right so now we have the encoder', 'start': 2301.02, 'duration': 5.31}, {'text': 'done and all we want to do now is we', 'start': 2303.03, 'duration': 5.4}, {'text': 'want to create the decoder and to make', 'start': 2306.33, 'duration': 7.77}, {'text': \"this I guess hopefully clear we're gonna\", 'start': 2308.43, 'duration': 9.87}, {'text': \"do the decoder block first so we're\", 'start': 2314.1, 'duration': 7.16}, {'text': 'going to do any module', 'start': 2318.3, 'duration': 2.96}, {'text': 'then do in it we are sending the embed', 'start': 2324.13, 'duration': 7.77}, {'text': 'size heads forward expansion dropout and', 'start': 2327.459, 'duration': 7.01}, {'text': 'device', 'start': 2331.9, 'duration': 2.569}, {'text': 'the super of decoder block self dot in', 'start': 2335.089, 'duration': 11.321}, {'text': 'it like this and so', 'start': 2341.69, 'duration': 6.46}, {'text': \"or that the first thing we're going to\", 'start': 2346.41, 'duration': 3.75}, {'text': \"do is we're going to send it through an\", 'start': 2348.15, 'duration': 4.26}, {'text': \"attention layer then we're going to do\", 'start': 2350.16, 'duration': 4.02}, {'text': \"the normalization and then we're just\", 'start': 2352.41, 'duration': 5.909}, {'text': 'going to use the transformer block so we', 'start': 2354.18, 'duration': 8.52}, {'text': \"can we can do self dot norm is or let's\", 'start': 2358.319, 'duration': 5.821}, {'text': 'do a tension first so step that', 'start': 2362.7, 'duration': 7.349}, {'text': 'attention is self attention of embed', 'start': 2364.14, 'duration': 12.12}, {'text': 'size comma heads and then the norm is', 'start': 2370.049, 'duration': 9.361}, {'text': 'just going to be an mayor norm of embed', 'start': 2376.26, 'duration': 5.329}, {'text': 'size', 'start': 2379.41, 'duration': 2.179}, {'text': 'and then transformer block will just be', 'start': 2381.75, 'duration': 7.68}, {'text': \"transform a block of let's see embed\", 'start': 2385.88, 'duration': 7.81}, {'text': 'sized heads dropout and then forward', 'start': 2389.43, 'duration': 6.49}, {'text': 'expansion', 'start': 2393.69, 'duration': 4.21}, {'text': \"and also we're just gonna do our drop\", 'start': 2395.92, 'duration': 4.409}, {'text': 'out so and then that drop out', 'start': 2397.9, 'duration': 5.699}, {'text': \"I'll drop out now ready to do the\", 'start': 2400.329, 'duration': 5.48}, {'text': \"forward part so we're going to do\", 'start': 2403.599, 'duration': 4.95}, {'text': \"forward and we're gonna do X we're gonna\", 'start': 2405.809, 'duration': 7.02}, {'text': 'send in value and and key and then this', 'start': 2408.549, 'duration': 6.601}, {'text': 'marks gonna send in a source mask and', 'start': 2412.829, 'duration': 4.451}, {'text': \"we're gonna send in a target mask all\", 'start': 2415.15, 'duration': 5.1}, {'text': 'right so the target mask is the one', 'start': 2417.28, 'duration': 4.86}, {'text': \"we've talked about and this one is uh I\", 'start': 2420.25, 'duration': 4.65}, {'text': 'guess this one is is essential you need', 'start': 2422.14, 'duration': 5.49}, {'text': 'to have this one the source mask is kind', 'start': 2424.9, 'duration': 7.8}, {'text': 'of option where you know if we if we', 'start': 2427.63, 'duration': 8.189}, {'text': 'send in a couple of examples then we', 'start': 2432.7, 'duration': 4.8}, {'text': 'need to Pat it to make sure that all of', 'start': 2435.819, 'duration': 4.381}, {'text': 'our equal lengths and then we can also', 'start': 2437.5, 'duration': 5.04}, {'text': \"send in a source mask so that we don't\", 'start': 2440.2, 'duration': 4.95}, {'text': \"compute we don't do Ness it unnecessary\", 'start': 2442.54, 'duration': 4.769}, {'text': 'computations for the ones that are', 'start': 2445.15, 'duration': 5.37}, {'text': \"padded so that one is optional but we're\", 'start': 2447.309, 'duration': 6.961}, {'text': 'gonna do it and then also remember in', 'start': 2450.52, 'duration': 6.99}, {'text': 'the decoder block we take X which is we', 'start': 2454.27, 'duration': 6.21}, {'text': 'take an input from up from our target', 'start': 2457.51, 'duration': 4.859}, {'text': 'and then we also take the value in the', 'start': 2460.48, 'duration': 3.48}, {'text': \"key and we're gonna get those from the\", 'start': 2462.369, 'duration': 3.871}, {'text': \"encoder that we've already run before\", 'start': 2463.96, 'duration': 9.0}, {'text': \"this so what we're gonna do is we're\", 'start': 2466.24, 'duration': 8.94}, {'text': 'going to do attention is just going to', 'start': 2472.96, 'duration': 7.31}, {'text': 'be self dot attention of of X', 'start': 2475.18, 'duration': 7.73}, {'text': 'and xxx because all of those are the', 'start': 2480.27, 'duration': 4.56}, {'text': \"same and then we're gonna send in the\", 'start': 2482.91, 'duration': 3.72}, {'text': \"target mask because remember that's the\", 'start': 2484.83, 'duration': 4.2}, {'text': 'mask multi-headed attention the first', 'start': 2486.63, 'duration': 4.8}, {'text': 'one in the decoder block and then the', 'start': 2489.03, 'duration': 4.62}, {'text': 'query is just going to be self to drop', 'start': 2491.43, 'duration': 5.25}, {'text': 'out of self-taught norm of attention', 'start': 2493.65, 'duration': 8.7}, {'text': 'plus X which is with the I guess with', 'start': 2496.68, 'duration': 9.6}, {'text': 'the skip connection and then out is just', 'start': 2502.35, 'duration': 6.12}, {'text': 'going to be self dot transformer block', 'start': 2506.28, 'duration': 6.45}, {'text': 'of the value the key and the query and', 'start': 2508.47, 'duration': 6.39}, {'text': 'then also the source mask which is', 'start': 2512.73, 'duration': 4.82}, {'text': \"optional but we're gonna do it and then\", 'start': 2514.86, 'duration': 8.37}, {'text': 'return out so and now we can do class of', 'start': 2517.55, 'duration': 9.01}, {'text': \"the decoder so so we're going to do\", 'start': 2523.23, 'duration': 7.62}, {'text': \"class decoder and in module we're gonna\", 'start': 2526.56, 'duration': 9.45}, {'text': \"do define in it we're gonna do target\", 'start': 2530.85, 'duration': 9.86}, {'text': 'vocab size and bed size on on layers', 'start': 2536.01, 'duration': 10.73}, {'text': 'heads a forward expansion', 'start': 2540.71, 'duration': 6.03}, {'text': 'dropout device and also max length', 'start': 2546.96, 'duration': 9.62}, {'text': \"um yeah so we're gonna do it like that\", 'start': 2553.52, 'duration': 6.62}, {'text': 'this looks a little bit weird', 'start': 2556.58, 'duration': 3.56}, {'text': 'all right so now we can start by writing', 'start': 2560.24, 'duration': 10.56}, {'text': \"in super of decoder and self and we're\", 'start': 2563.6, 'duration': 11.63}, {'text': 'gonna do underscore in it', 'start': 2570.8, 'duration': 6.38}, {'text': 'like this and then self-doubt device', 'start': 2575.23, 'duration': 5.79}, {'text': 'equals device setup that word embedding', 'start': 2577.18, 'duration': 7.04}, {'text': 'and is going to be and then dot', 'start': 2581.02, 'duration': 8.76}, {'text': 'embedding of target vocab size and then', 'start': 2584.22, 'duration': 7.57}, {'text': \"the embed size and then we're going to\", 'start': 2589.78, 'duration': 5.07}, {'text': \"do self dot position embedding it's\", 'start': 2591.79, 'duration': 6.18}, {'text': 'going to be a nun dot embedding of again', 'start': 2594.85, 'duration': 5.87}, {'text': 'max length', 'start': 2597.97, 'duration': 6.55}, {'text': 'and then the embed size', 'start': 2600.72, 'duration': 3.8}, {'text': 'and then self that lay a set of layers', 'start': 2604.79, 'duration': 6.829}, {'text': 'can be an endowed module list', 'start': 2607.19, 'duration': 8.47}, {'text': \"we're going to do a decoder block of\", 'start': 2611.619, 'duration': 7.341}, {'text': 'embed size', 'start': 2615.66, 'duration': 3.3}, {'text': 'heads forward expansion drop out and in', 'start': 2619.19, 'duration': 9.72}, {'text': \"the device and we're gonna do that for\", 'start': 2624.109, 'duration': 9.23}, {'text': 'you know in range of numb layers', 'start': 2628.91, 'duration': 4.429}, {'text': \"so that's going to be the layers and\", 'start': 2636.17, 'duration': 6.71}, {'text': \"we're going to do set up FC out\", 'start': 2638.36, 'duration': 4.52}, {'text': \"it's going to be a nonlinear of\", 'start': 2644.45, 'duration': 4.84}, {'text': 'sighs', 'start': 2647.42, 'duration': 5.82}, {'text': 'and then target vocab size', 'start': 2649.29, 'duration': 3.95}, {'text': \"and let's see kind of lost my track here\", 'start': 2653.28, 'duration': 5.04}, {'text': \"so we've done the layers and then yeah\", 'start': 2656.04, 'duration': 5.64}, {'text': \"so we're just going to do a last linear\", 'start': 2658.32, 'duration': 6.86}, {'text': \"layer so now we're done with the sort of\", 'start': 2661.68, 'duration': 5.61}, {'text': \"after the decoder block that's just\", 'start': 2665.18, 'duration': 5.58}, {'text': 'going to be another linear layer and', 'start': 2667.29, 'duration': 3.47}, {'text': \"we're just going to do itself that\", 'start': 2670.92, 'duration': 4.49}, {'text': 'dropout is and then drop out of drop out', 'start': 2672.03, 'duration': 6.38}, {'text': \"then again we're going to do forward\", 'start': 2675.41, 'duration': 8.08}, {'text': \"self and we're gonna do X here for input\", 'start': 2678.41, 'duration': 9.84}, {'text': \"to the decoder and then we're gonna do\", 'start': 2683.49, 'duration': 8.73}, {'text': \"the encoder out we're gonna send an\", 'start': 2688.25, 'duration': 5.95}, {'text': \"encoder out and then we're gonna do\", 'start': 2692.22, 'duration': 5.88}, {'text': 'source mask and then target mask', 'start': 2694.2, 'duration': 6.96}, {'text': \"and let's see her so we're gonna do n\", 'start': 2698.1, 'duration': 6.51}, {'text': 'comma sequence length equals x shape', 'start': 2701.16, 'duration': 5.88}, {'text': \"we're gonna create the positions which\", 'start': 2704.61, 'duration': 4.22}, {'text': 'are just going to beat or shut arrange', 'start': 2707.04, 'duration': 6.84}, {'text': 'zero sequence sequence Ling and then', 'start': 2708.83, 'duration': 7.45}, {'text': \"we're just going to expand n comma\", 'start': 2713.88, 'duration': 4.8}, {'text': 'sequence length so that we have it over', 'start': 2716.28, 'duration': 4.61}, {'text': \"all of the training examples we're gonna\", 'start': 2718.68, 'duration': 5.13}, {'text': \"get it to CUDA if it's a bit available\", 'start': 2720.89, 'duration': 5.23}, {'text': \"and then we're just gonna do X is self\", 'start': 2723.81, 'duration': 8.25}, {'text': \"to drop out of self that word let's see\", 'start': 2726.12, 'duration': 9.27}, {'text': 'self that word embedding of X and then', 'start': 2732.06, 'duration': 6.8}, {'text': 'plus self doubt position embedding of', 'start': 2735.39, 'duration': 6.78}, {'text': \"positions and then you know we're just\", 'start': 2738.86, 'duration': 5.67}, {'text': 'gonna do for layer in set up layers', 'start': 2742.17, 'duration': 8.43}, {'text': \"we're gonna do X is layer of X and then\", 'start': 2744.53, 'duration': 8.86}, {'text': \"so that's going to be the let's see that\", 'start': 2750.6, 'duration': 4.86}, {'text': \"it's going to be the value to the decode\", 'start': 2753.39, 'duration': 3.99}, {'text': 'so the input to the decoder block and', 'start': 2755.46, 'duration': 3.81}, {'text': \"then we're just gonna send in the\", 'start': 2757.38, 'duration': 5.37}, {'text': \"encoder out encoder out for the let's\", 'start': 2759.27, 'duration': 3.9}, {'text': 'see it', 'start': 2762.75, 'duration': 5.04}, {'text': 'for the value and the key alright so I', 'start': 2763.17, 'duration': 7.95}, {'text': 'guess we can do this so here we have X', 'start': 2767.79, 'duration': 5.52}, {'text': 'we have value in the key and those are', 'start': 2771.12, 'duration': 5.22}, {'text': 'gonna be you know the same thing which', 'start': 2773.31, 'duration': 8.37}, {'text': \"is output from the encoder so let's see\", 'start': 2776.34, 'duration': 8.18}, {'text': \"here we're gonna do\", 'start': 2781.68, 'duration': 2.84}, {'text': \"also we're gonna send in let's see the\", 'start': 2785.18, 'duration': 5.629}, {'text': 'source mask and then the target mask', 'start': 2786.589, 'duration': 4.22}, {'text': 'and then out is just going', 'start': 2792.94, 'duration': 5.34}, {'text': 'be self-taught fully connected out of X', 'start': 2794.51, 'duration': 8.36}, {'text': \"so we're gonna get we're gonna get a\", 'start': 2798.28, 'duration': 8.22}, {'text': 'prediction of which word is is next', 'start': 2802.87, 'duration': 6.04}, {'text': 'which is going to be dependent on our', 'start': 2806.5, 'duration': 6.64}, {'text': 'vocabulary size for target all right I', 'start': 2808.91, 'duration': 5.67}, {'text': 'think this is gonna be a long video but', 'start': 2813.14, 'duration': 3.48}, {'text': \"you know now we've done the encoder with\", 'start': 2814.58, 'duration': 4.32}, {'text': \"on the decoder and we're ready to put\", 'start': 2816.62, 'duration': 5.67}, {'text': 'this together and do class transformer', 'start': 2818.9, 'duration': 8.25}, {'text': \"of end off module and we're gonna send\", 'start': 2822.29, 'duration': 8.48}, {'text': 'do some init here', 'start': 2827.15, 'duration': 3.62}, {'text': \"and we're gonna do our self we're gonna\", 'start': 2831.94, 'duration': 7.889}, {'text': \"do source of vocab sighs we're gonna do\", 'start': 2836.65, 'duration': 6.3}, {'text': \"target vocab sighs we're gonna do source\", 'start': 2839.829, 'duration': 6.72}, {'text': \"pad index we're going to target pad\", 'start': 2842.95, 'duration': 6.75}, {'text': 'index because those are necessary to', 'start': 2846.549, 'duration': 5.461}, {'text': \"compute the mask that we're going to use\", 'start': 2849.7, 'duration': 5.25}, {'text': \"and then the embed size we're going to\", 'start': 2852.01, 'duration': 7.25}, {'text': 'set to 512', 'start': 2854.95, 'duration': 4.31}, {'text': 'we can use 2:56 as we did and then', 'start': 2862.32, 'duration': 7.83}, {'text': 'number of layers we can set to 6 the', 'start': 2865.8, 'duration': 7.46}, {'text': 'forward expansion', 'start': 2870.15, 'duration': 3.11}, {'text': 'to default for the heads because the', 'start': 2874.86, 'duration': 4.92}, {'text': 'default eight drop out we can set', 'start': 2877.5, 'duration': 6.44}, {'text': 'default zero device we can set default', 'start': 2879.78, 'duration': 9.15}, {'text': 'CUDA and then max length is gonna be', 'start': 2883.94, 'duration': 7.53}, {'text': \"let's say a hundred\", 'start': 2888.93, 'duration': 6.01}, {'text': \"then we're just going to call super of\", 'start': 2891.47, 'duration': 11.66}, {'text': 'transformer self dot in it', 'start': 2894.94, 'duration': 8.19}, {'text': 'and then we need to just first define', 'start': 2903.17, 'duration': 5.429}, {'text': \"the encoder so we're gonna do self that\", 'start': 2906.41, 'duration': 8.25}, {'text': 'encoder is gonna be in the encoder and', 'start': 2908.599, 'duration': 7.651}, {'text': \"we're just going to send in the source\", 'start': 2914.66, 'duration': 5.97}, {'text': 'vocabularies source vocabulary size the', 'start': 2916.25, 'duration': 9.26}, {'text': 'embed size the number of layers heads', 'start': 2920.63, 'duration': 10.32}, {'text': 'odd device forward expansion dropout and', 'start': 2925.51, 'duration': 8.62}, {'text': \"then max length all right that's just\", 'start': 2930.95, 'duration': 7.139}, {'text': 'how we defined the input ordering of the', 'start': 2934.13, 'duration': 5.76}, {'text': 'encoder then we can do the same for the', 'start': 2938.089, 'duration': 3.601}, {'text': \"decoder it's just going to be decoder\", 'start': 2939.89, 'duration': 4.61}, {'text': \"and we're gonna send in a target book\", 'start': 2941.69, 'duration': 6.47}, {'text': 'target vocabulary size the embed size', 'start': 2944.5, 'duration': 9.4}, {'text': 'number of layers heads the forward', 'start': 2948.16, 'duration': 9.1}, {'text': 'expansion the drop out the device and', 'start': 2953.9, 'duration': 9.63}, {'text': 'then the max length like that and then', 'start': 2957.26, 'duration': 9.71}, {'text': 'we can also just', 'start': 2963.53, 'duration': 3.44}, {'text': 'that we can also you know do the source', 'start': 2967.93, 'duration': 7.66}, {'text': 'had index is source had index self that', 'start': 2970.55, 'duration': 10.49}, {'text': 'target pad index is target pad index and', 'start': 2975.59, 'duration': 10.13}, {'text': 'self dot device is just device', 'start': 2981.04, 'duration': 6.54}, {'text': 'and so what we got to do first is we got', 'start': 2985.72, 'duration': 3.96}, {'text': 'to make a function to make them source', 'start': 2987.58, 'duration': 4.5}, {'text': 'masks and then the target mask so we can', 'start': 2989.68, 'duration': 4.919}, {'text': \"do make source masks and we're just\", 'start': 2992.08, 'duration': 5.97}, {'text': \"gonna send in the source and we're gonna\", 'start': 2994.599, 'duration': 5.211}, {'text': 'do a source mask', 'start': 2998.05, 'duration': 4.98}, {'text': \"it's gonna be source and then we're\", 'start': 2999.81, 'duration': 9.49}, {'text': 'gonna do on C not equal to self-taught', 'start': 3003.03, 'duration': 9.03}, {'text': \"source pad index and then we're just\", 'start': 3009.3, 'duration': 5.25}, {'text': 'gonna do one squeeze one and then', 'start': 3012.06, 'duration': 6.45}, {'text': 'unscrews to so the source mass is going', 'start': 3014.55, 'duration': 6.41}, {'text': 'to be n', 'start': 3018.51, 'duration': 2.45}, {'text': \"the shop shapes add up so we're going to\", 'start': 3022.09, 'duration': 5.7}, {'text': \"N 1 1 and then the source length that's\", 'start': 3024.52, 'duration': 4.8}, {'text': 'all the shapes are going to be and then', 'start': 3027.79, 'duration': 4.14}, {'text': \"we're just gonna return source mask dot\", 'start': 3029.32, 'duration': 5.03}, {'text': 'to self dot device', 'start': 3031.93, 'duration': 6.48}, {'text': 'so again if it is a source pad index', 'start': 3034.35, 'duration': 6.43}, {'text': \"then it's gonna be set set to zero and\", 'start': 3038.41, 'duration': 4.74}, {'text': \"if it's not it's gonna be set to one and\", 'start': 3040.78, 'duration': 5.04}, {'text': \"that's how we define the source mask you\", 'start': 3043.15, 'duration': 6.12}, {'text': 'can also use I guess the opposite but', 'start': 3045.82, 'duration': 5.67}, {'text': \"that's just how we define it here and\", 'start': 3049.27, 'duration': 4.29}, {'text': \"then we're going to define make target\", 'start': 3051.49, 'duration': 6.03}, {'text': 'mask and really are we gonna do here is', 'start': 3053.56, 'duration': 6.6}, {'text': \"we're gonna get the target ling by\", 'start': 3057.52, 'duration': 6.63}, {'text': \"targeted shape and then we're gonna do\", 'start': 3060.16, 'duration': 8.1}, {'text': \"target mask it's gonna be we're gonna do\", 'start': 3064.15, 'duration': 8.67}, {'text': \"a a triangular matrix so we're gonna do\", 'start': 3068.26, 'duration': 8.88}, {'text': \"torch dot triangular I'll lower and we\", 'start': 3072.82, 'duration': 8.07}, {'text': \"and we're going to torch that once so\", 'start': 3077.14, 'duration': 7.17}, {'text': 'the element values on this lower', 'start': 3080.89, 'duration': 5.64}, {'text': 'triangular matrix is going to be just', 'start': 3084.31, 'duration': 4.77}, {'text': \"values of 1 and then it's gonna be\", 'start': 3086.53, 'duration': 6.18}, {'text': \"targeting and target length and we're\", 'start': 3089.08, 'duration': 5.01}, {'text': 'just gonna do another thing which is', 'start': 3092.71, 'duration': 4.58}, {'text': 'expanded so that we have one for each', 'start': 3094.09, 'duration': 8.94}, {'text': 'training example and then we can just do', 'start': 3097.29, 'duration': 10.95}, {'text': 'return target mask da to self dot device', 'start': 3103.03, 'duration': 5.21}, {'text': \"we also going to define forward and it's\", 'start': 3109.73, 'duration': 6.27}, {'text': 'gonna be source and target so now we', 'start': 3112.22, 'duration': 6.18}, {'text': 'send in the source and target and', 'start': 3116.0, 'duration': 4.56}, {'text': \"basically you know we're gonna do source\", 'start': 3118.4, 'duration': 5.87}, {'text': 'mask is self that make source mask of', 'start': 3120.56, 'duration': 7.71}, {'text': 'source and then target mask is gonna be', 'start': 3124.27, 'duration': 9.04}, {'text': 'self that make target mask of target so', 'start': 3128.27, 'duration': 6.33}, {'text': 'I guess that makes sense', 'start': 3133.31, 'duration': 3.45}, {'text': \"and then we're just gonna do encode\", 'start': 3134.6, 'duration': 4.41}, {'text': \"source it's gonna be self that encoder\", 'start': 3136.76, 'duration': 6.63}, {'text': 'of source and source mask and the', 'start': 3139.01, 'duration': 7.53}, {'text': \"decoder or let's say out it's just gonna\", 'start': 3143.39, 'duration': 6.18}, {'text': 'be self the decoder of target and then', 'start': 3146.54, 'duration': 5.85}, {'text': 'encode source and then the source mask', 'start': 3149.57, 'duration': 6.09}, {'text': \"and the target mask and then we're gonna\", 'start': 3152.39, 'duration': 7.8}, {'text': 'do return out and yeah so now we created', 'start': 3155.66, 'duration': 9.959}, {'text': 'the entire transformer so what we can do', 'start': 3160.19, 'duration': 7.26}, {'text': \"is I have an example right here and I'm\", 'start': 3165.619, 'duration': 3.451}, {'text': \"gonna copy that in so we don't have to\", 'start': 3167.45, 'duration': 4.95}, {'text': 'write that but just say a a I guess a', 'start': 3169.07, 'duration': 6.93}, {'text': 'small example that just a toy example to', 'start': 3172.4, 'duration': 8.88}, {'text': 'see that it runs so we have device CUDA', 'start': 3176.0, 'duration': 7.49}, {'text': 'and I have some example right here and', 'start': 3181.28, 'duration': 5.55}, {'text': 'so the one is for the star token zero is', 'start': 3183.49, 'duration': 6.04}, {'text': 'for padding and two would be some end of', 'start': 3186.83, 'duration': 5.82}, {'text': 'sentence so this is just random and this', 'start': 3189.53, 'duration': 5.43}, {'text': 'is no data but just as an example and', 'start': 3192.65, 'duration': 4.5}, {'text': 'then we have two examples right here and', 'start': 3194.96, 'duration': 4.05}, {'text': 'then we have some target right here not', 'start': 3197.15, 'duration': 4.77}, {'text': 'necessarily the same shape as the input', 'start': 3199.01, 'duration': 6.06}, {'text': 'and then we just define the source path', 'start': 3201.92, 'duration': 5.01}, {'text': 'index we define what is the vocabulary', 'start': 3205.07, 'duration': 4.89}, {'text': \"size so here I use you know I doesn't I\", 'start': 3206.93, 'duration': 7.2}, {'text': \"don't go above 10 so 9 is the maximum\", 'start': 3209.96, 'duration': 6.6}, {'text': 'right here so the source vocabulary size', 'start': 3214.13, 'duration': 4.95}, {'text': 'is 10 then we just do model and we do', 'start': 3216.56, 'duration': 5.37}, {'text': 'transformer of sort of a capillary and', 'start': 3219.08, 'duration': 7.11}, {'text': 'then pad index and then we just do model', 'start': 3221.93, 'duration': 7.74}, {'text': 'and we send in X and we also send in the', 'start': 3226.19, 'duration': 6.27}, {'text': 'target except the target will be shifted', 'start': 3229.67, 'duration': 7.02}, {'text': \"by by one so that it it doesn't have the\", 'start': 3232.46, 'duration': 6.63}, {'text': 'end of sentence token because we wanted', 'start': 3236.69, 'duration': 5.93}, {'text': 'to learn to predict the end of sentence', 'start': 3239.09, 'duration': 5.75}, {'text': \"but I guess that's more how you would\", 'start': 3242.62, 'duration': 4.31}, {'text': 'use the transformer and this is sort of', 'start': 3244.84, 'duration': 5.34}, {'text': 'more focus on how to actually implement', 'start': 3246.93, 'duration': 6.67}, {'text': 'it from scratch but this would be used', 'start': 3250.18, 'duration': 5.76}, {'text': 'later on you know to send to cross', 'start': 3253.6, 'duration': 5.57}, {'text': 'entropy and etc', 'start': 3255.94, 'duration': 3.23}, {'text': 'yeah but not to take too much focus on', 'start': 3259.63, 'duration': 6.599}, {'text': \"that so let's try and run this there's\", 'start': 3264.069, 'duration': 3.48}, {'text': \"probably gonna be a few errors we've\", 'start': 3266.229, 'duration': 3.99}, {'text': 'written a lot of code and yeah so', 'start': 3267.549, 'duration': 8.76}, {'text': 'invalid syntax we can do line 119 yes', 'start': 3270.219, 'duration': 8.961}, {'text': \"we're gonna have to do\", 'start': 3276.309, 'duration': 2.871}, {'text': \"what we're gonna do like this\", 'start': 3279.23, 'duration': 5.12}, {'text': 'and we run it again no more', 'start': 3285.64, 'duration': 7.75}, {'text': 'okay yeah I remember so I need to do see', 'start': 3288.99, 'duration': 8.64}, {'text': 'so and the import torture error was just', 'start': 3293.39, 'duration': 6.43}, {'text': \"because I didn't I had to activate my\", 'start': 3297.63, 'duration': 5.94}, {'text': 'corner environment but the first but', 'start': 3299.82, 'duration': 5.25}, {'text': 'then we get another error when I rerun', 'start': 3303.57, 'duration': 4.59}, {'text': 'it so that error is because in this line', 'start': 3305.07, 'duration': 6.15}, {'text': 'right here in line 25 for the query', 'start': 3308.16, 'duration': 7.56}, {'text': 'reshape we use the key length which we', 'start': 3311.22, 'duration': 7.0}, {'text': 'should use the', 'start': 3315.72, 'duration': 5.649}, {'text': \"the query linked right here and let's\", 'start': 3318.22, 'duration': 6.02}, {'text': 'see if this runs now', 'start': 3321.369, 'duration': 2.871}, {'text': 'all right so it took a bit a little bit', 'start': 3326.37, 'duration': 4.5}, {'text': 'of time but I found the air now so here', 'start': 3328.17, 'duration': 4.74}, {'text': \"this one wasn't actually causing there\", 'start': 3330.87, 'duration': 4.26}, {'text': \"but this is an error so we're gonna do\", 'start': 3332.91, 'duration': 5.19}, {'text': 'the transformer block for a couple of', 'start': 3335.13, 'duration': 6.57}, {'text': \"layers we're gonna do a range of num\", 'start': 3338.1, 'duration': 6.87}, {'text': 'layers like that and then what caused', 'start': 3341.7, 'duration': 7.35}, {'text': 'the error is that in the decoder somehow', 'start': 3344.97, 'duration': 7.41}, {'text': 'I returned I forgot to return so turn', 'start': 3349.05, 'duration': 5.79}, {'text': 'out also there was one very important', 'start': 3352.38, 'duration': 3.96}, {'text': 'thing that I missed in the self', 'start': 3354.84, 'duration': 3.81}, {'text': 'attention which is that after we do the', 'start': 3356.34, 'duration': 4.14}, {'text': 'reshape we need to send them through the', 'start': 3358.65, 'duration': 4.34}, {'text': \"linear layers so we're gonna do values\", 'start': 3360.48, 'duration': 6.03}, {'text': 'equals self-taught values of values and', 'start': 3362.99, 'duration': 8.95}, {'text': 'then keys equals self dot keys of keys', 'start': 3366.51, 'duration': 10.1}, {'text': 'and queries equal self dot queries of', 'start': 3371.94, 'duration': 9.77}, {'text': 'queries and if we now run this', 'start': 3376.61, 'duration': 5.1}, {'text': 'we we get the the the correct shape and', 'start': 3382.099, 'duration': 6.841}, {'text': \"I've tried I've also tried to train this\", 'start': 3385.989, 'duration': 6.671}, {'text': 'on some translation tasks and it seems', 'start': 3388.94, 'duration': 6.089}, {'text': 'to work similarly as a Python', 'start': 3392.66, 'duration': 5.099}, {'text': 'implementation but of course there might', 'start': 3395.029, 'duration': 6.24}, {'text': 'be some error in it that no I might have', 'start': 3397.759, 'duration': 7.56}, {'text': 'missed but so you know there there you', 'start': 3401.269, 'duration': 5.641}, {'text': 'have it the transformer from scratch', 'start': 3405.319, 'duration': 3.96}, {'text': 'this was definitely a more challenging', 'start': 3406.91, 'duration': 7.349}, {'text': 'video and definitely for me at least so', 'start': 3409.279, 'duration': 8.161}, {'text': 'you know hopefully this was helpful for', 'start': 3414.259, 'duration': 5.701}, {'text': 'a couple of you and yeah thank you so', 'start': 3417.44, 'duration': 5.72}, {'text': 'much for watching the video', 'start': 3419.96, 'duration': 3.2}, {'text': '[Music]', 'start': 3424.74, 'duration': 6.41}]\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "  \n",
    "srt = YouTubeTranscriptApi.get_transcript(\"U0s0f995w14\")\n",
    "print(srt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if you want to get the subtitles of the multiple videos, just add multiple video codes with comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "  \n",
    "srt = YouTubeTranscriptApi.get_transcript(\"U0s0f995w14\", \"frfrgthyhy\", \"grfdreefe\")\n",
    "print(srt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For getting transcripts of more than one video we can pass them using commas, as in YouTubeTranscriptApi.get_transcript(videoid1, Videoid2, .)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write subtitles of a YouTube video in a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    " \n",
    "srt = YouTubeTranscriptApi.get_transcript(\"U0s0f995w14\")\n",
    " \n",
    "\n",
    "with open(\"subtitles.txt\", \"w\") as f:\n",
    "   \n",
    "    for i in srt:\n",
    "        f.write(\"{}\\n\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write subtitles of a YouTube video in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "\n",
    "\n",
    "transcript = YouTubeTranscriptApi.get_transcript(\"U0s0f995w14\")\n",
    "\n",
    "formatter = TextFormatter()\n",
    "\n",
    "csv_formatted = formatter.format_transcript(transcript)\n",
    "\n",
    "\n",
    "with open('subtitle.csv', 'w', encoding='utf-8') as csv_file:\n",
    "    csv_file.write(csv_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarly we can convert it into json format also. \n",
    "#### the base class to inherit from when creating your own formatter.\n",
    "#### 1.from youtube_transcript_api.formatters import Formatter\n",
    "\n",
    "#### some provided subclasses, each outputs a different string format.\n",
    "#### 2.from youtube_transcript_api.formatters import JSONFormatter\n",
    "#### 3.from youtube_transcript_api.formatters import TextFormatter\n",
    "#### 4.from youtube_transcript_api.formatters import WebVTTFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting Subtitles using youtube_Dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=6DwPQO65BIA&thttps://www.youtube.com/watch?v=6DwPQO65BIA\n",
      "[youtube] 6DwPQO65BIA: Downloading webpage\n",
      "[youtube] 6DwPQO65BIA: Downloading MPD manifest\n",
      "Download Successful!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "import youtube_dl\n",
    "ydl_opts = {\n",
    "'writesubtitles': True,\n",
    "'writeautomaticsub': True,\n",
    "'subtitle': '--write-sub --sub-lang en',\n",
    "'skip_download': True,\n",
    "}\n",
    "url = input(\"https://www.youtube.com/watch?v=6DwPQO65BIA&t\")\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([url])\n",
    "print(\"Download Successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting subtitle using google speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = mp.VideoFileClip(r\"top_pytorch_ques.mp4\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|          | 268/795749 [00:00<04:57, 2675.87it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in converted.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "clip.audio.write_audiofile(r\"converted.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = sr.AudioFile(\"converted.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with audio as source:\n",
    "  audio_file = r.record(source)            ## Error with this command, working on this one.\n",
    "result = r.recognize_google(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
